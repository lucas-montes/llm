{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e310db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/v1bkq59yxcf4ys3np121vpmb2abgnh72-python3.12-torch-2.7.0/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /build/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2e196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[1,2],[3,4]]).float()\n",
    "b=torch.tensor([[1,2,3,4]])\n",
    "head_dim = 10\n",
    "theta_base=10_000\n",
    "dtype=torch.float32\n",
    "assert head_dim % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f890112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 2., 2.],\n",
       "        [3., 3., 4., 4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat_interleave(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736dfec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((3, 3,3), dtype=torch.bool).repeat_interleave(2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c214b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones((3, 3), dtype=torch.bool)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934079ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask_global (future is masked: j > i)\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 1 1 1 1 1 1 1\n",
    "        #     1:  0 0 1 1 1 1 1 1\n",
    "        #     2:  0 0 0 1 1 1 1 1\n",
    "        #     3:  0 0 0 0 1 1 1 1\n",
    "        #     4:  0 0 0 0 0 1 1 1\n",
    "        #     5:  0 0 0 0 0 0 1 1\n",
    "        #     6:  0 0 0 0 0 0 0 1\n",
    "        #     7:  0 0 0 0 0 0 0 0\n",
    "mask_global = torch.triu(ones, diagonal=1)\n",
    "mask_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93fd12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# far_past (too far back is masked: i - j >= sliding_window)\n",
    "# where sliding_window = 4\n",
    "#     j:  0 1 2 3 4 5 6 7\n",
    "#  i\n",
    "#     0:  0 0 0 0 0 0 0 0\n",
    "#     1:  0 0 0 0 0 0 0 0\n",
    "#     2:  0 0 0 0 0 0 0 0\n",
    "#     3:  0 0 0 0 0 0 0 0\n",
    "#     4:  1 0 0 0 0 0 0 0\n",
    "#     5:  1 1 0 0 0 0 0 0\n",
    "#     6:  1 1 1 0 0 0 0 0\n",
    "#     7:  1 1 1 1 0 0 0 0\n",
    "far_past = torch.triu(ones, diagonal=512).T\n",
    "far_past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "498d2e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False,  True,  True],\n",
       "         [False, False,  True],\n",
       "         [False, False, False]]),\n",
       " tensor([[False,  True,  True],\n",
       "         [False, False,  True],\n",
       "         [False, False, False]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local (sliding_window) = future OR far-past\n",
    "# mask_local\n",
    "#     j:  0 1 2 3 4 5 6 7\n",
    "# i\n",
    "# 0:      0 1 1 1 1 1 1 1\n",
    "# 1:      0 0 1 1 1 1 1 1\n",
    "# 2:      0 0 0 1 1 1 1 1\n",
    "# 3:      0 0 0 0 1 1 1 1\n",
    "# 4:      1 0 0 0 0 1 1 1\n",
    "# 5:      1 1 0 0 0 0 1 1\n",
    "# 6:      1 1 1 0 0 0 0 1\n",
    "# 7:      1 1 1 1 0 0 0 0\n",
    "mask_local = mask_global | far_past\n",
    "mask_global, mask_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7251e8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf],\n",
       "        [2., 3., -inf],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[2,3,4],[2,3,4]]).float().masked_fill(mask_global, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1c4366d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2],\n",
       "         [4, 4],\n",
       "         [3, 3],\n",
       "         [4, 4]],\n",
       "\n",
       "        [[2, 2],\n",
       "         [4, 4],\n",
       "         [3, 3],\n",
       "         [4, 4]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[[2,4,3,4],[2,4,3,4]],[[2,4,3,4],[2,4,3,4]]]).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "948b09e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(-2, 1).stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab1c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0243dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = torch.arange(8, dtype=dtype)\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ef8170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2141ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_freq[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cbca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04],\n",
       "        [2.0000e+00, 3.1698e-01, 5.0238e-02, 7.9621e-03, 1.2619e-03],\n",
       "        [3.0000e+00, 4.7547e-01, 7.5357e-02, 1.1943e-02, 1.8929e-03],\n",
       "        [4.0000e+00, 6.3396e-01, 1.0048e-01, 1.5924e-02, 2.5238e-03],\n",
       "        [5.0000e+00, 7.9245e-01, 1.2559e-01, 1.9905e-02, 3.1548e-03],\n",
       "        [6.0000e+00, 9.5094e-01, 1.5071e-01, 2.3886e-02, 3.7857e-03],\n",
       "        [7.0000e+00, 1.1094e+00, 1.7583e-01, 2.7867e-02, 4.4167e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the angles\n",
    "angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70065006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04, 1.0000e+00,\n",
       "         1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04],\n",
       "        [2.0000e+00, 3.1698e-01, 5.0238e-02, 7.9621e-03, 1.2619e-03, 2.0000e+00,\n",
       "         3.1698e-01, 5.0238e-02, 7.9621e-03, 1.2619e-03],\n",
       "        [3.0000e+00, 4.7547e-01, 7.5357e-02, 1.1943e-02, 1.8929e-03, 3.0000e+00,\n",
       "         4.7547e-01, 7.5357e-02, 1.1943e-02, 1.8929e-03],\n",
       "        [4.0000e+00, 6.3396e-01, 1.0048e-01, 1.5924e-02, 2.5238e-03, 4.0000e+00,\n",
       "         6.3396e-01, 1.0048e-01, 1.5924e-02, 2.5238e-03],\n",
       "        [5.0000e+00, 7.9245e-01, 1.2559e-01, 1.9905e-02, 3.1548e-03, 5.0000e+00,\n",
       "         7.9245e-01, 1.2559e-01, 1.9905e-02, 3.1548e-03],\n",
       "        [6.0000e+00, 9.5094e-01, 1.5071e-01, 2.3886e-02, 3.7857e-03, 6.0000e+00,\n",
       "         9.5094e-01, 1.5071e-01, 2.3886e-02, 3.7857e-03],\n",
       "        [7.0000e+00, 1.1094e+00, 1.7583e-01, 2.7867e-02, 4.4167e-03, 7.0000e+00,\n",
       "         1.1094e+00, 1.7583e-01, 2.7867e-02, 4.4167e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles2 = torch.cat([angles, angles], dim=1)\n",
    "angles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb2978c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000],\n",
       "        [ 0.5403,  0.9875,  0.9997,  1.0000,  1.0000,  0.5403,  0.9875,  0.9997,\n",
       "          1.0000,  1.0000],\n",
       "        [-0.4161,  0.9502,  0.9987,  1.0000,  1.0000, -0.4161,  0.9502,  0.9987,\n",
       "          1.0000,  1.0000],\n",
       "        [-0.9900,  0.8891,  0.9972,  0.9999,  1.0000, -0.9900,  0.8891,  0.9972,\n",
       "          0.9999,  1.0000],\n",
       "        [-0.6536,  0.8057,  0.9950,  0.9999,  1.0000, -0.6536,  0.8057,  0.9950,\n",
       "          0.9999,  1.0000],\n",
       "        [ 0.2837,  0.7021,  0.9921,  0.9998,  1.0000,  0.2837,  0.7021,  0.9921,\n",
       "          0.9998,  1.0000],\n",
       "        [ 0.9602,  0.5809,  0.9887,  0.9997,  1.0000,  0.9602,  0.5809,  0.9887,\n",
       "          0.9997,  1.0000],\n",
       "        [ 0.7539,  0.4452,  0.9846,  0.9996,  1.0000,  0.7539,  0.4452,  0.9846,\n",
       "          0.9996,  1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(angles2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af023779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "\n",
    "    # Compute the inverse frequencies\n",
    "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "\n",
    "    # Generate position indices\n",
    "    positions = torch.arange(context_length, dtype=dtype)\n",
    "\n",
    "    # Compute the angles\n",
    "    angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
    "\n",
    "    # Expand angles to match the head_dim\n",
    "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
    "\n",
    "    # Precompute sine and cosine\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "\n",
    "    return cos, sin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b5cbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rope(x, cos, sin):\n",
    "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
    "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    # Split x into first half and second half\n",
    "    x1 = x[..., : head_dim // 2]  # First half\n",
    "    x2 = x[..., head_dim // 2 :]  # Second half\n",
    "\n",
    "    # Adjust sin and cos shapes\n",
    "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
    "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply the rotary transformation\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    # It's ok to use lower-precision after applying cos and sin rotation\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3ac46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-6, bias=False):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # Gemma3 stores zero-centered weights and uses (1 + weight) during forward\n",
    "        self.scale = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Match HF Gemma3: compute norm in float32, then scale by (1 + w)\n",
    "        input_dtype = x.dtype\n",
    "        x_f = x.float()\n",
    "        var = x_f.pow(2).mean(dim=-1, keepdim=True)\n",
    "        x_norm = x_f * torch.rsqrt(var + self.eps)\n",
    "        out = x_norm * (1.0 + self.scale.float())\n",
    "\n",
    "        if self.shift is not None:\n",
    "            out = out + self.shift.float()\n",
    "\n",
    "        return out.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b023c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n",
    "        query_pre_attn_scalar=None, dtype=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.group_size = num_heads // num_kv_groups\n",
    "\n",
    "        if head_dim is None:\n",
    "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
    "            head_dim = d_in // num_heads\n",
    "\n",
    "        self.head_dim = head_dim\n",
    "        self.d_out = num_heads * head_dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n",
    "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
    "\n",
    "        if qk_norm:\n",
    "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "        else:\n",
    "            self.q_norm = self.k_norm = None\n",
    "\n",
    "        if query_pre_attn_scalar is not None:\n",
    "            self.scaling = (query_pre_attn_scalar) ** -0.5\n",
    "        else:\n",
    "            self.scaling = (head_dim) ** -0.5\n",
    "\n",
    "\n",
    "    def forward(self, x, mask, cos, sin):\n",
    "        b, num_tokens, _ = x.shape\n",
    "\n",
    "        # Apply projections\n",
    "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)(1,3,1024)\n",
    "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
    "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
    "\n",
    "        print(queries)\n",
    "        print(\"initial querys shape:\", queries.shape)\n",
    "\n",
    "        # Reshape\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        print(queries)\n",
    "        print(\"after view querys shape:\", queries.shape)\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # (b, num_heads, num_tokens, head_dim)\n",
    "        print(queries)\n",
    "        print(\"after transpose querys shape:\", queries.shape)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Optional normalization\n",
    "        if self.q_norm:\n",
    "            queries = self.q_norm(queries)\n",
    "        if self.k_norm:\n",
    "            keys = self.k_norm(keys)\n",
    "\n",
    "        # Apply RoPE\n",
    "        queries = apply_rope(queries, cos, sin)\n",
    "        keys = apply_rope(keys, cos, sin)\n",
    "\n",
    "        # Expand K and V to match number of heads\n",
    "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
    "        values = values.repeat_interleave(self.group_size, dim=1)\n",
    "\n",
    "        # Scale queries\n",
    "        queries = queries * self.scaling\n",
    "\n",
    "        # Attention\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
    "        return self.out_proj(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073253a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: dict, attn_type: str):\n",
    "        super().__init__()\n",
    "        self.attn_type = attn_type\n",
    "\n",
    "        self.att = GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            qk_norm=cfg[\"qk_norm\"],\n",
    "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
    "            dtype=cfg[\"dtype\"],\n",
    "        )\n",
    "        # self.ff = FeedForward(cfg)\n",
    "        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        mask_global,\n",
    "        mask_local,\n",
    "        cos_global,\n",
    "        sin_global,\n",
    "        cos_local,\n",
    "        sin_local,\n",
    "    ):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.input_layernorm(x)\n",
    "\n",
    "        if self.attn_type == \"sliding_attention\":\n",
    "            attn_mask = mask_local\n",
    "            cos = cos_local\n",
    "            sin = sin_local\n",
    "        else:\n",
    "            attn_mask = mask_global\n",
    "            cos = cos_global\n",
    "            sin = sin_global\n",
    "\n",
    "        x_attn = self.att(x, attn_mask, cos, sin)\n",
    "        x_attn = self.post_attention_layernorm(x_attn)\n",
    "        x = shortcut + x_attn\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x_ffn = self.pre_feedforward_layernorm(x)\n",
    "        # x_ffn = self.ff(x_ffn)\n",
    "        x_ffn = self.post_feedforward_layernorm(x_ffn)\n",
    "        x = shortcut + x_ffn\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f680a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma3Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n",
    "\n",
    "        # Main model parameters\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n",
    "        ])\n",
    "\n",
    "        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # Reusuable utilities\n",
    "        cos_local, sin_local = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_local_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        cos_global, sin_global = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n",
    "        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n",
    "        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n",
    "        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n",
    "\n",
    "    def _create_masks(self, seq_len, device):\n",
    "        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n",
    "\n",
    "        # mask_global (future is masked: j > i)\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 1 1 1 1 1 1 1\n",
    "        #     1:  0 0 1 1 1 1 1 1\n",
    "        #     2:  0 0 0 1 1 1 1 1\n",
    "        #     3:  0 0 0 0 1 1 1 1\n",
    "        #     4:  0 0 0 0 0 1 1 1\n",
    "        #     5:  0 0 0 0 0 0 1 1\n",
    "        #     6:  0 0 0 0 0 0 0 1\n",
    "        #     7:  0 0 0 0 0 0 0 0\n",
    "        mask_global = torch.triu(ones, diagonal=1)\n",
    "\n",
    "        # far_past (too far back is masked: i - j >= sliding_window)\n",
    "        # where sliding_window = 4\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 0 0 0 0 0 0 0\n",
    "        #     1:  0 0 0 0 0 0 0 0\n",
    "        #     2:  0 0 0 0 0 0 0 0\n",
    "        #     3:  0 0 0 0 0 0 0 0\n",
    "        #     4:  1 0 0 0 0 0 0 0\n",
    "        #     5:  1 1 0 0 0 0 0 0\n",
    "        #     6:  1 1 1 0 0 0 0 0\n",
    "        #     7:  1 1 1 1 0 0 0 0\n",
    "        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n",
    "\n",
    "        # Local (sliding_window) = future OR far-past\n",
    "        # mask_local\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        # i\n",
    "        # 0:      0 1 1 1 1 1 1 1\n",
    "        # 1:      0 0 1 1 1 1 1 1\n",
    "        # 2:      0 0 0 1 1 1 1 1\n",
    "        # 3:      0 0 0 0 1 1 1 1\n",
    "        # 4:      1 0 0 0 0 1 1 1\n",
    "        # 5:      1 1 0 0 0 0 1 1\n",
    "        # 6:      1 1 1 0 0 0 0 1\n",
    "        # 7:      1 1 1 1 0 0 0 0\n",
    "        mask_local = mask_global | far_past\n",
    "        return mask_global, mask_local\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Forward pass\n",
    "        b, seq_len = input_ids.shape\n",
    "        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n",
    "        mask_global, mask_local = self._create_masks(seq_len, x.device)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(\n",
    "                x,\n",
    "                mask_global=mask_global,\n",
    "                mask_local=mask_local,\n",
    "                cos_global=self.cos_global,\n",
    "                sin_global=self.sin_global,\n",
    "                cos_local=self.cos_local,\n",
    "                sin_local=self.sin_local,\n",
    "            )\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc38cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"vocab_size\": 144,\n",
    "    \"context_length\": 68,\n",
    "    \"emb_dim\": 4,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 2,\n",
    "    \"hidden_dim\": 8,\n",
    "    \"head_dim\": 8,\n",
    "    \"qk_norm\": True,\n",
    "    \"n_kv_groups\": 1,\n",
    "    \"rope_local_base\": 10_000.0,\n",
    "    \"rope_base\": 1_000_000.0,\n",
    "    \"sliding_window\": 512,\n",
    "      \"layer_types\": [\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\"\n",
    "    ],\n",
    "    \"dtype\": torch.bfloat16,\n",
    "    \"query_pre_attn_scalar\": 256,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ddea97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            qk_norm=cfg[\"qk_norm\"],\n",
    "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
    "            dtype=cfg[\"dtype\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72954090",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = TransformerBlock(cfg, \"attn_type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
