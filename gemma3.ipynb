{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b280ab-b61f-4d1a-bf7e-44e5f9ed3a5c",
   "metadata": {
    "id": "e1b280ab-b61f-4d1a-bf7e-44e5f9ed3a5c"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde77f2-6af3-4781-8597-89ecd3f41a52",
   "metadata": {
    "id": "efde77f2-6af3-4781-8597-89ecd3f41a52"
   },
   "source": [
    "# Gemma 3 270M From Scratch (A Standalone Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d",
   "metadata": {
    "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d"
   },
   "source": [
    "- This notebook is purposefully minimal and focuses on the code to re-implement Gemma 3 270M in pure PyTorch without relying on other external LLM libraries\n",
    "- For more information, see the official [Gemma 3 270M model card](https://huggingface.co/google/gemma-3-270m)\n",
    "\n",
    "- Below is a side-by-side comparison with Qwen3 0.6B as a reference model; if you are interested in the Qwen3 0.6B standalone notebook, you can find it [here](../11_qwen3)\n",
    "<br>\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gemma3/gemma3-vs-qwen3.webp?1\">\n",
    "  \n",
    "  \n",
    "- About the code:\n",
    "  - all code is my own code, mapping the Gemma 3 architecture onto the model code implemented in my [Build A Large Language Model (From Scratch)](http://mng.bz/orYv) book; the code is released under a permissive open-source Apache 2.0 license (see [LICENSE.txt](https://github.com/rasbt/LLMs-from-scratch/blob/main/LICENSE.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c201adb-747e-437b-9a62-442802941e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
    "outputId": "4f762354-e0a3-4cc2-e5d4-e61a227a202c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub version: 0.30.2\n",
      "tokenizers version: 0.21.1\n",
      "torch version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"huggingface_hub\",  # to download pretrained weights\n",
    "    \"tokenizers\",       # to implement the tokenizer\n",
    "    \"torch\",            # to implement the model\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e96fbb-8e16-4f6d-835f-c6159321280b",
   "metadata": {},
   "source": [
    "- This notebook supports both the base model and the instructmodel; which model to use can be controlled via the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a90338-624a-4706-aa55-6b4358070194",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_INSTRUCT_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653410a6-dd2b-4eb2-a722-23d9782e726d",
   "metadata": {
    "id": "653410a6-dd2b-4eb2-a722-23d9782e726d"
   },
   "source": [
    "&nbsp;\n",
    "# 1. Architecture code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82076c21-9331-4dcd-b017-42b046cf1a60",
   "metadata": {
    "id": "82076c21-9331-4dcd-b017-42b046cf1a60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/v1bkq59yxcf4ys3np121vpmb2abgnh72-python3.12-torch-2.7.0/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /build/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x)\n",
    "        x = nn.functional.gelu(x_fc1, approximate=\"tanh\") * x_fc2\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56715760-37e1-433e-89da-04864c139a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-6, bias=False):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # Gemma3 stores zero-centered weights and uses (1 + weight) during forward\n",
    "        self.scale = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Match HF Gemma3: compute norm in float32, then scale by (1 + w)\n",
    "        input_dtype = x.dtype\n",
    "        x_f = x.float()\n",
    "        var = x_f.pow(2).mean(dim=-1, keepdim=True)\n",
    "        x_norm = x_f * torch.rsqrt(var + self.eps)\n",
    "        out = x_norm * (1.0 + self.scale.float())\n",
    "\n",
    "        if self.shift is not None:\n",
    "            out = out + self.shift.float()\n",
    "\n",
    "        return out.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9a346f-5826-4083-9162-abd56afc03f0",
   "metadata": {
    "id": "4b9a346f-5826-4083-9162-abd56afc03f0"
   },
   "outputs": [],
   "source": [
    "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "\n",
    "    # Compute the inverse frequencies\n",
    "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "\n",
    "    # Generate position indices\n",
    "    positions = torch.arange(context_length, dtype=dtype)\n",
    "\n",
    "    # Compute the angles\n",
    "    angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
    "\n",
    "    # Expand angles to match the head_dim\n",
    "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
    "\n",
    "    # Precompute sine and cosine\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "\n",
    "    return cos, sin\n",
    "\n",
    "\n",
    "def apply_rope(x, cos, sin):\n",
    "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
    "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    # Split x into first half and second half\n",
    "    x1 = x[..., : head_dim // 2]  # First half\n",
    "    x2 = x[..., head_dim // 2 :]  # Second half\n",
    "\n",
    "    # Adjust sin and cos shapes\n",
    "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
    "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply the rotary transformation\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    # It's ok to use lower-precision after applying cos and sin rotation\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb",
   "metadata": {
    "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb"
   },
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n",
    "        query_pre_attn_scalar=None, dtype=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.group_size = num_heads // num_kv_groups\n",
    "\n",
    "        if head_dim is None:\n",
    "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
    "            head_dim = d_in // num_heads\n",
    "\n",
    "        self.head_dim = head_dim\n",
    "        self.d_out = num_heads * head_dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n",
    "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
    "\n",
    "        if qk_norm:\n",
    "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "        else:\n",
    "            self.q_norm = self.k_norm = None\n",
    "\n",
    "        if query_pre_attn_scalar is not None:\n",
    "            self.scaling = (query_pre_attn_scalar) ** -0.5\n",
    "        else:\n",
    "            self.scaling = (head_dim) ** -0.5\n",
    "\n",
    "\n",
    "    def forward(self, x, mask, cos, sin):\n",
    "        b, num_tokens, _ = x.shape\n",
    "\n",
    "        # Apply projections\n",
    "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)(1,3,1024)\n",
    "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
    "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
    "\n",
    "        print(queries)\n",
    "        print(\"initial querys shape:\", queries.shape)\n",
    "\n",
    "        print(\"params\", b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Reshape\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        print(queries)\n",
    "        print(\"after view querys shape:\", queries.shape)\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # (b, num_heads, num_tokens, head_dim)\n",
    "        print(queries)\n",
    "        print(\"after transpose querys shape:\", queries.shape)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Optional normalization\n",
    "        if self.q_norm:\n",
    "            queries = self.q_norm(queries)\n",
    "        if self.k_norm:\n",
    "            keys = self.k_norm(keys)\n",
    "\n",
    "        # Apply RoPE\n",
    "        queries = apply_rope(queries, cos, sin)\n",
    "        keys = apply_rope(keys, cos, sin)\n",
    "\n",
    "        # Expand K and V to match number of heads\n",
    "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
    "        values = values.repeat_interleave(self.group_size, dim=1)\n",
    "\n",
    "        # Scale queries\n",
    "        queries = queries * self.scaling\n",
    "\n",
    "        # Attention\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
    "        return self.out_proj(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9",
   "metadata": {
    "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: dict, attn_type: str):\n",
    "        super().__init__()\n",
    "        self.attn_type = attn_type\n",
    "\n",
    "        self.att = GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            qk_norm=cfg[\"qk_norm\"],\n",
    "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
    "            dtype=cfg[\"dtype\"],\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        mask_global,\n",
    "        mask_local,\n",
    "        cos_global,\n",
    "        sin_global,\n",
    "        cos_local,\n",
    "        sin_local,\n",
    "    ):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.input_layernorm(x)\n",
    "\n",
    "        if self.attn_type == \"sliding_attention\":\n",
    "            attn_mask = mask_local\n",
    "            cos = cos_local\n",
    "            sin = sin_local\n",
    "        else:\n",
    "            attn_mask = mask_global\n",
    "            cos = cos_global\n",
    "            sin = sin_global\n",
    "\n",
    "        x_attn = self.att(x, attn_mask, cos, sin)\n",
    "        x_attn = self.post_attention_layernorm(x_attn)\n",
    "        x = shortcut + x_attn\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x_ffn = self.pre_feedforward_layernorm(x)\n",
    "        x_ffn = self.ff(x_ffn)\n",
    "        x_ffn = self.post_feedforward_layernorm(x_ffn)\n",
    "        x = shortcut + x_ffn\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4",
   "metadata": {
    "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4"
   },
   "outputs": [],
   "source": [
    "class Gemma3Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n",
    "\n",
    "        # Main model parameters\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n",
    "        ])\n",
    "\n",
    "        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # Reusuable utilities\n",
    "        cos_local, sin_local = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_local_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        cos_global, sin_global = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n",
    "        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n",
    "        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n",
    "        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n",
    "\n",
    "    def _create_masks(self, seq_len, device):\n",
    "        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n",
    "\n",
    "        print(\"ones:\", ones)\n",
    "        print(\"ones shape:\", (seq_len, seq_len))\n",
    "\n",
    "        # mask_global (future is masked: j > i)\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 1 1 1 1 1 1 1\n",
    "        #     1:  0 0 1 1 1 1 1 1\n",
    "        #     2:  0 0 0 1 1 1 1 1\n",
    "        #     3:  0 0 0 0 1 1 1 1\n",
    "        #     4:  0 0 0 0 0 1 1 1\n",
    "        #     5:  0 0 0 0 0 0 1 1\n",
    "        #     6:  0 0 0 0 0 0 0 1\n",
    "        #     7:  0 0 0 0 0 0 0 0\n",
    "        mask_global = torch.triu(ones, diagonal=1)\n",
    "\n",
    "        # far_past (too far back is masked: i - j >= sliding_window)\n",
    "        # where sliding_window = 4\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 0 0 0 0 0 0 0\n",
    "        #     1:  0 0 0 0 0 0 0 0\n",
    "        #     2:  0 0 0 0 0 0 0 0\n",
    "        #     3:  0 0 0 0 0 0 0 0\n",
    "        #     4:  1 0 0 0 0 0 0 0\n",
    "        #     5:  1 1 0 0 0 0 0 0\n",
    "        #     6:  1 1 1 0 0 0 0 0\n",
    "        #     7:  1 1 1 1 0 0 0 0\n",
    "        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n",
    "\n",
    "        # Local (sliding_window) = future OR far-past\n",
    "        # mask_local\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        # i\n",
    "        # 0:      0 1 1 1 1 1 1 1\n",
    "        # 1:      0 0 1 1 1 1 1 1\n",
    "        # 2:      0 0 0 1 1 1 1 1\n",
    "        # 3:      0 0 0 0 1 1 1 1\n",
    "        # 4:      1 0 0 0 0 1 1 1\n",
    "        # 5:      1 1 0 0 0 0 1 1\n",
    "        # 6:      1 1 1 0 0 0 0 1\n",
    "        # 7:      1 1 1 1 0 0 0 0\n",
    "        mask_local = mask_global | far_past\n",
    "        return mask_global, mask_local\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Forward pass\n",
    "        _, seq_len = input_ids.shape\n",
    "        print(\"input_ids shape:\", input_ids.shape)\n",
    "        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n",
    "        mask_global, mask_local = self._create_masks(seq_len, x.device)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(\n",
    "                x,\n",
    "                mask_global=mask_global,\n",
    "                mask_local=mask_local,\n",
    "                cos_global=self.cos_global,\n",
    "                sin_global=self.sin_global,\n",
    "                cos_local=self.cos_local,\n",
    "                sin_local=self.sin_local,\n",
    "            )\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d201f-74ad-4d63-ab9c-601b00674a48",
   "metadata": {
    "id": "be2d201f-74ad-4d63-ab9c-601b00674a48"
   },
   "source": [
    "&nbsp;\n",
    "# 2. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa142fa-b375-4e78-b392-2072ced666f3",
   "metadata": {
    "id": "caa142fa-b375-4e78-b392-2072ced666f3"
   },
   "outputs": [],
   "source": [
    "GEMMA3_CONFIG_270M = {\n",
    "    \"vocab_size\": 44,\n",
    "    \"context_length\": 8,\n",
    "    \"emb_dim\": 4,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 18,\n",
    "    \"hidden_dim\": 8,\n",
    "    \"head_dim\": 8,\n",
    "    \"qk_norm\": True,\n",
    "    \"n_kv_groups\": 1,\n",
    "    \"rope_local_base\": 10_000.0,\n",
    "    \"rope_base\": 1_000_000.0,\n",
    "    \"sliding_window\": 512,\n",
    "      \"layer_types\": [\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\"\n",
    "    ],\n",
    "    \"dtype\": torch.bfloat16,\n",
    "    \"query_pre_attn_scalar\": 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156253fe-aacd-4da2-8f13-705f05c4b11e",
   "metadata": {
    "id": "156253fe-aacd-4da2-8f13-705f05c4b11e"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = Gemma3Model(GEMMA3_CONFIG_270M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf86265-4e9d-4024-9ed0-99076944e304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3Model(\n",
       "  (tok_emb): Embedding(44, 4)\n",
       "  (blocks): ModuleList(\n",
       "    (0-17): 18 x TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_query): Linear(in_features=4, out_features=32, bias=False)\n",
       "        (W_key): Linear(in_features=4, out_features=8, bias=False)\n",
       "        (W_value): Linear(in_features=4, out_features=8, bias=False)\n",
       "        (out_proj): Linear(in_features=32, out_features=4, bias=False)\n",
       "        (q_norm): RMSNorm()\n",
       "        (k_norm): RMSNorm()\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=4, out_features=8, bias=False)\n",
       "        (fc2): Linear(in_features=4, out_features=8, bias=False)\n",
       "        (fc3): Linear(in_features=8, out_features=4, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm()\n",
       "  (out_head): Linear(in_features=4, out_features=44, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aca91d-4bee-45ce-993a-4ec5393abe2b",
   "metadata": {},
   "source": [
    "- A quick check that the forward pass works before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0a6b7-b688-42c9-966e-c223d34db99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 3])\n",
      "ones: tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n",
      "ones shape: (3, 3)\n",
      "tensor([[[ 0.7383,  0.4590,  0.3379, -0.1719,  0.0024,  0.0132,  0.9023,\n",
      "          -0.8086, -0.7461, -0.2559,  1.0938, -0.6367,  0.0347,  0.7539,\n",
      "           0.3105, -0.4219, -0.9453, -0.5312, -0.0771,  0.1904,  0.6211,\n",
      "          -0.7734,  0.3281,  1.0625, -0.3242, -0.4766,  0.2754, -0.6211,\n",
      "           0.8516, -0.3418, -1.0078,  0.3438],\n",
      "         [ 0.2852,  0.3242, -0.0037, -0.0498,  0.8945, -0.0322,  0.8438,\n",
      "           0.1328, -0.7383,  0.6289,  0.8906,  0.8555,  0.5586,  0.4141,\n",
      "           0.9023, -0.5781, -0.6289, -0.5547,  0.6992,  0.4473,  1.0000,\n",
      "          -0.4785,  0.0991, -0.0649,  0.7773,  0.2021, -0.2559, -0.4922,\n",
      "           0.7617,  0.0240, -0.8398,  0.3203],\n",
      "         [-0.7422, -0.4316, -0.2637,  0.1719, -0.2812,  0.0791, -1.0547,\n",
      "           0.6055,  0.8555,  0.0452, -1.1953,  0.2041, -0.1562, -0.8359,\n",
      "          -0.4766,  0.5117,  0.9414,  0.6680, -0.1699, -0.2852, -0.7852,\n",
      "           0.7930, -0.3770, -0.8047,  0.0061,  0.3047, -0.1533,  0.6289,\n",
      "          -0.9336,  0.3418,  1.0469, -0.4727]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.7383,  0.4590,  0.3379, -0.1719,  0.0024,  0.0132,  0.9023,\n",
      "           -0.8086],\n",
      "          [-0.7461, -0.2559,  1.0938, -0.6367,  0.0347,  0.7539,  0.3105,\n",
      "           -0.4219],\n",
      "          [-0.9453, -0.5312, -0.0771,  0.1904,  0.6211, -0.7734,  0.3281,\n",
      "            1.0625],\n",
      "          [-0.3242, -0.4766,  0.2754, -0.6211,  0.8516, -0.3418, -1.0078,\n",
      "            0.3438]],\n",
      "\n",
      "         [[ 0.2852,  0.3242, -0.0037, -0.0498,  0.8945, -0.0322,  0.8438,\n",
      "            0.1328],\n",
      "          [-0.7383,  0.6289,  0.8906,  0.8555,  0.5586,  0.4141,  0.9023,\n",
      "           -0.5781],\n",
      "          [-0.6289, -0.5547,  0.6992,  0.4473,  1.0000, -0.4785,  0.0991,\n",
      "           -0.0649],\n",
      "          [ 0.7773,  0.2021, -0.2559, -0.4922,  0.7617,  0.0240, -0.8398,\n",
      "            0.3203]],\n",
      "\n",
      "         [[-0.7422, -0.4316, -0.2637,  0.1719, -0.2812,  0.0791, -1.0547,\n",
      "            0.6055],\n",
      "          [ 0.8555,  0.0452, -1.1953,  0.2041, -0.1562, -0.8359, -0.4766,\n",
      "            0.5117],\n",
      "          [ 0.9414,  0.6680, -0.1699, -0.2852, -0.7852,  0.7930, -0.3770,\n",
      "           -0.8047],\n",
      "          [ 0.0061,  0.3047, -0.1533,  0.6289, -0.9336,  0.3418,  1.0469,\n",
      "           -0.4727]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.7383,  0.4590,  0.3379, -0.1719,  0.0024,  0.0132,  0.9023,\n",
      "           -0.8086],\n",
      "          [ 0.2852,  0.3242, -0.0037, -0.0498,  0.8945, -0.0322,  0.8438,\n",
      "            0.1328],\n",
      "          [-0.7422, -0.4316, -0.2637,  0.1719, -0.2812,  0.0791, -1.0547,\n",
      "            0.6055]],\n",
      "\n",
      "         [[-0.7461, -0.2559,  1.0938, -0.6367,  0.0347,  0.7539,  0.3105,\n",
      "           -0.4219],\n",
      "          [-0.7383,  0.6289,  0.8906,  0.8555,  0.5586,  0.4141,  0.9023,\n",
      "           -0.5781],\n",
      "          [ 0.8555,  0.0452, -1.1953,  0.2041, -0.1562, -0.8359, -0.4766,\n",
      "            0.5117]],\n",
      "\n",
      "         [[-0.9453, -0.5312, -0.0771,  0.1904,  0.6211, -0.7734,  0.3281,\n",
      "            1.0625],\n",
      "          [-0.6289, -0.5547,  0.6992,  0.4473,  1.0000, -0.4785,  0.0991,\n",
      "           -0.0649],\n",
      "          [ 0.9414,  0.6680, -0.1699, -0.2852, -0.7852,  0.7930, -0.3770,\n",
      "           -0.8047]],\n",
      "\n",
      "         [[-0.3242, -0.4766,  0.2754, -0.6211,  0.8516, -0.3418, -1.0078,\n",
      "            0.3438],\n",
      "          [ 0.7773,  0.2021, -0.2559, -0.4922,  0.7617,  0.0240, -0.8398,\n",
      "            0.3203],\n",
      "          [ 0.0061,  0.3047, -0.1533,  0.6289, -0.9336,  0.3418,  1.0469,\n",
      "           -0.4727]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.5391, -0.0825, -0.8125, -0.3770,  0.3926,  0.0439,  0.0199,\n",
      "           0.6172,  0.5859, -0.1895, -0.3574,  1.1484,  0.2598,  0.5977,\n",
      "           0.6406, -0.6797,  0.1992, -0.5391,  0.8398,  0.7539, -0.3926,\n",
      "           0.7695,  0.8555, -1.0625,  0.6602, -0.0593, -0.4609,  1.1406,\n",
      "           0.6992,  0.7695,  0.8359, -0.4609],\n",
      "         [ 0.1738, -0.6016, -1.1094,  0.8242,  0.7500,  0.1123, -0.4238,\n",
      "           1.2500, -0.1943,  0.0352, -0.0352, -0.3535,  0.5117,  0.2871,\n",
      "          -0.2637, -0.9570,  0.2715,  0.4473,  0.2852, -0.9648, -0.6289,\n",
      "           0.8086,  0.5820,  0.1641,  1.1250,  0.8477,  0.3496, -0.1455,\n",
      "          -1.0234,  1.0938, -0.4414,  0.3438],\n",
      "         [ 0.0894,  1.0469,  0.5195, -0.6758, -0.0342,  0.3203,  0.4590,\n",
      "          -0.7227, -0.2676, -0.8281, -0.3574,  0.1206, -0.2949, -0.9023,\n",
      "           0.6055,  0.7266,  0.2441, -0.1387,  0.1226,  0.3164,  0.5859,\n",
      "          -0.8242, -0.2373, -0.6836, -0.8789, -0.9922, -0.1748,  0.4004,\n",
      "           0.5781, -1.2266,  0.8398,  0.0459]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.5391, -0.0825, -0.8125, -0.3770,  0.3926,  0.0439,  0.0199,\n",
      "            0.6172],\n",
      "          [ 0.5859, -0.1895, -0.3574,  1.1484,  0.2598,  0.5977,  0.6406,\n",
      "           -0.6797],\n",
      "          [ 0.1992, -0.5391,  0.8398,  0.7539, -0.3926,  0.7695,  0.8555,\n",
      "           -1.0625],\n",
      "          [ 0.6602, -0.0593, -0.4609,  1.1406,  0.6992,  0.7695,  0.8359,\n",
      "           -0.4609]],\n",
      "\n",
      "         [[ 0.1738, -0.6016, -1.1094,  0.8242,  0.7500,  0.1123, -0.4238,\n",
      "            1.2500],\n",
      "          [-0.1943,  0.0352, -0.0352, -0.3535,  0.5117,  0.2871, -0.2637,\n",
      "           -0.9570],\n",
      "          [ 0.2715,  0.4473,  0.2852, -0.9648, -0.6289,  0.8086,  0.5820,\n",
      "            0.1641],\n",
      "          [ 1.1250,  0.8477,  0.3496, -0.1455, -1.0234,  1.0938, -0.4414,\n",
      "            0.3438]],\n",
      "\n",
      "         [[ 0.0894,  1.0469,  0.5195, -0.6758, -0.0342,  0.3203,  0.4590,\n",
      "           -0.7227],\n",
      "          [-0.2676, -0.8281, -0.3574,  0.1206, -0.2949, -0.9023,  0.6055,\n",
      "            0.7266],\n",
      "          [ 0.2441, -0.1387,  0.1226,  0.3164,  0.5859, -0.8242, -0.2373,\n",
      "           -0.6836],\n",
      "          [-0.8789, -0.9922, -0.1748,  0.4004,  0.5781, -1.2266,  0.8398,\n",
      "            0.0459]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.5391, -0.0825, -0.8125, -0.3770,  0.3926,  0.0439,  0.0199,\n",
      "            0.6172],\n",
      "          [ 0.1738, -0.6016, -1.1094,  0.8242,  0.7500,  0.1123, -0.4238,\n",
      "            1.2500],\n",
      "          [ 0.0894,  1.0469,  0.5195, -0.6758, -0.0342,  0.3203,  0.4590,\n",
      "           -0.7227]],\n",
      "\n",
      "         [[ 0.5859, -0.1895, -0.3574,  1.1484,  0.2598,  0.5977,  0.6406,\n",
      "           -0.6797],\n",
      "          [-0.1943,  0.0352, -0.0352, -0.3535,  0.5117,  0.2871, -0.2637,\n",
      "           -0.9570],\n",
      "          [-0.2676, -0.8281, -0.3574,  0.1206, -0.2949, -0.9023,  0.6055,\n",
      "            0.7266]],\n",
      "\n",
      "         [[ 0.1992, -0.5391,  0.8398,  0.7539, -0.3926,  0.7695,  0.8555,\n",
      "           -1.0625],\n",
      "          [ 0.2715,  0.4473,  0.2852, -0.9648, -0.6289,  0.8086,  0.5820,\n",
      "            0.1641],\n",
      "          [ 0.2441, -0.1387,  0.1226,  0.3164,  0.5859, -0.8242, -0.2373,\n",
      "           -0.6836]],\n",
      "\n",
      "         [[ 0.6602, -0.0593, -0.4609,  1.1406,  0.6992,  0.7695,  0.8359,\n",
      "           -0.4609],\n",
      "          [ 1.1250,  0.8477,  0.3496, -0.1455, -1.0234,  1.0938, -0.4414,\n",
      "            0.3438],\n",
      "          [-0.8789, -0.9922, -0.1748,  0.4004,  0.5781, -1.2266,  0.8398,\n",
      "            0.0459]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.4570,  0.2656, -0.6602,  0.6094,  1.1250, -0.9375, -0.5469,\n",
      "          -0.2422, -0.3594, -0.1152, -0.1030,  0.0659,  0.6445,  0.4766,\n",
      "           0.2012, -0.5938, -0.7266,  0.6719, -0.4004, -0.4238,  0.8320,\n",
      "          -0.1689, -0.0574, -0.8398, -0.2871, -0.3438,  0.1167, -0.3789,\n",
      "          -0.1348, -1.0703, -0.6367, -0.0674],\n",
      "         [-0.6602,  0.2949, -1.1016, -0.5820,  1.3047, -0.8242, -0.6289,\n",
      "           0.6328, -0.2256, -1.1172,  0.3828, -0.8398,  0.0737, -0.1816,\n",
      "           0.1582, -0.3594, -0.6211, -0.2637,  0.6055,  0.4062, -0.8164,\n",
      "           0.1187,  0.0422, -0.2871,  0.2695,  0.3086,  0.6836,  0.3027,\n",
      "          -0.7773, -0.0359,  0.4062, -0.8125],\n",
      "         [ 0.7266, -1.0625,  0.9062,  0.2168, -0.6953,  1.2188,  0.5312,\n",
      "          -0.3262,  0.2949,  0.6953, -0.3379,  0.2832, -0.3340, -0.0981,\n",
      "          -0.1494,  0.7344,  1.1172, -0.1611, -0.3516,  0.0289, -0.1318,\n",
      "           0.0713,  0.0947,  0.9609, -0.2227, -0.3086, -0.4453, -0.2217,\n",
      "           0.9219,  0.3633, -0.0378,  0.7891]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.4570,  0.2656, -0.6602,  0.6094,  1.1250, -0.9375, -0.5469,\n",
      "           -0.2422],\n",
      "          [-0.3594, -0.1152, -0.1030,  0.0659,  0.6445,  0.4766,  0.2012,\n",
      "           -0.5938],\n",
      "          [-0.7266,  0.6719, -0.4004, -0.4238,  0.8320, -0.1689, -0.0574,\n",
      "           -0.8398],\n",
      "          [-0.2871, -0.3438,  0.1167, -0.3789, -0.1348, -1.0703, -0.6367,\n",
      "           -0.0674]],\n",
      "\n",
      "         [[-0.6602,  0.2949, -1.1016, -0.5820,  1.3047, -0.8242, -0.6289,\n",
      "            0.6328],\n",
      "          [-0.2256, -1.1172,  0.3828, -0.8398,  0.0737, -0.1816,  0.1582,\n",
      "           -0.3594],\n",
      "          [-0.6211, -0.2637,  0.6055,  0.4062, -0.8164,  0.1187,  0.0422,\n",
      "           -0.2871],\n",
      "          [ 0.2695,  0.3086,  0.6836,  0.3027, -0.7773, -0.0359,  0.4062,\n",
      "           -0.8125]],\n",
      "\n",
      "         [[ 0.7266, -1.0625,  0.9062,  0.2168, -0.6953,  1.2188,  0.5312,\n",
      "           -0.3262],\n",
      "          [ 0.2949,  0.6953, -0.3379,  0.2832, -0.3340, -0.0981, -0.1494,\n",
      "            0.7344],\n",
      "          [ 1.1172, -0.1611, -0.3516,  0.0289, -0.1318,  0.0713,  0.0947,\n",
      "            0.9609],\n",
      "          [-0.2227, -0.3086, -0.4453, -0.2217,  0.9219,  0.3633, -0.0378,\n",
      "            0.7891]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.4570,  0.2656, -0.6602,  0.6094,  1.1250, -0.9375, -0.5469,\n",
      "           -0.2422],\n",
      "          [-0.6602,  0.2949, -1.1016, -0.5820,  1.3047, -0.8242, -0.6289,\n",
      "            0.6328],\n",
      "          [ 0.7266, -1.0625,  0.9062,  0.2168, -0.6953,  1.2188,  0.5312,\n",
      "           -0.3262]],\n",
      "\n",
      "         [[-0.3594, -0.1152, -0.1030,  0.0659,  0.6445,  0.4766,  0.2012,\n",
      "           -0.5938],\n",
      "          [-0.2256, -1.1172,  0.3828, -0.8398,  0.0737, -0.1816,  0.1582,\n",
      "           -0.3594],\n",
      "          [ 0.2949,  0.6953, -0.3379,  0.2832, -0.3340, -0.0981, -0.1494,\n",
      "            0.7344]],\n",
      "\n",
      "         [[-0.7266,  0.6719, -0.4004, -0.4238,  0.8320, -0.1689, -0.0574,\n",
      "           -0.8398],\n",
      "          [-0.6211, -0.2637,  0.6055,  0.4062, -0.8164,  0.1187,  0.0422,\n",
      "           -0.2871],\n",
      "          [ 1.1172, -0.1611, -0.3516,  0.0289, -0.1318,  0.0713,  0.0947,\n",
      "            0.9609]],\n",
      "\n",
      "         [[-0.2871, -0.3438,  0.1167, -0.3789, -0.1348, -1.0703, -0.6367,\n",
      "           -0.0674],\n",
      "          [ 0.2695,  0.3086,  0.6836,  0.3027, -0.7773, -0.0359,  0.4062,\n",
      "           -0.8125],\n",
      "          [-0.2227, -0.3086, -0.4453, -0.2217,  0.9219,  0.3633, -0.0378,\n",
      "            0.7891]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.2109,  0.4258, -0.1846,  0.7695, -0.5117, -0.6992,  0.1123,\n",
      "          -0.1260,  0.6992, -0.1670, -0.7812,  0.8555, -0.3320,  0.0031,\n",
      "           0.9609, -0.3828, -0.3770, -0.3398,  0.4258,  0.2930, -0.7422,\n",
      "          -1.0000,  0.7461,  0.0771, -0.0181, -0.2344, -0.2471, -0.0569,\n",
      "           0.9062, -0.1768, -0.9102,  0.6523],\n",
      "         [ 0.2021,  0.5898,  0.1006, -0.1357, -1.0859,  0.1670, -0.8555,\n",
      "          -0.4785,  1.2578,  0.6758, -0.7930, -0.2227, -0.5156, -0.4609,\n",
      "          -0.6016,  0.3633, -0.1523,  0.3828, -0.5195,  0.0082,  0.5664,\n",
      "          -0.7031, -0.3691,  0.6602,  0.5000, -0.5508, -0.6562,  0.5664,\n",
      "           0.8945,  0.1543, -0.9961, -0.8633],\n",
      "         [ 0.1138, -0.8359, -0.1167, -0.1963,  0.5742,  0.5938,  0.4629,\n",
      "           0.6641, -0.5859, -0.2871,  1.0156, -0.3594,  0.7266,  0.1943,\n",
      "           0.2197,  0.0284,  0.3750, -0.1157, -0.1748, -0.6250,  0.4316,\n",
      "           0.8047, -0.0613, -0.9688, -0.8594,  1.0000,  0.8125, -0.9766,\n",
      "          -0.8477, -0.1484,  1.0391, -0.2061]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.2109,  0.4258, -0.1846,  0.7695, -0.5117, -0.6992,  0.1123,\n",
      "           -0.1260],\n",
      "          [ 0.6992, -0.1670, -0.7812,  0.8555, -0.3320,  0.0031,  0.9609,\n",
      "           -0.3828],\n",
      "          [-0.3770, -0.3398,  0.4258,  0.2930, -0.7422, -1.0000,  0.7461,\n",
      "            0.0771],\n",
      "          [-0.0181, -0.2344, -0.2471, -0.0569,  0.9062, -0.1768, -0.9102,\n",
      "            0.6523]],\n",
      "\n",
      "         [[ 0.2021,  0.5898,  0.1006, -0.1357, -1.0859,  0.1670, -0.8555,\n",
      "           -0.4785],\n",
      "          [ 1.2578,  0.6758, -0.7930, -0.2227, -0.5156, -0.4609, -0.6016,\n",
      "            0.3633],\n",
      "          [-0.1523,  0.3828, -0.5195,  0.0082,  0.5664, -0.7031, -0.3691,\n",
      "            0.6602],\n",
      "          [ 0.5000, -0.5508, -0.6562,  0.5664,  0.8945,  0.1543, -0.9961,\n",
      "           -0.8633]],\n",
      "\n",
      "         [[ 0.1138, -0.8359, -0.1167, -0.1963,  0.5742,  0.5938,  0.4629,\n",
      "            0.6641],\n",
      "          [-0.5859, -0.2871,  1.0156, -0.3594,  0.7266,  0.1943,  0.2197,\n",
      "            0.0284],\n",
      "          [ 0.3750, -0.1157, -0.1748, -0.6250,  0.4316,  0.8047, -0.0613,\n",
      "           -0.9688],\n",
      "          [-0.8594,  1.0000,  0.8125, -0.9766, -0.8477, -0.1484,  1.0391,\n",
      "           -0.2061]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.2109,  0.4258, -0.1846,  0.7695, -0.5117, -0.6992,  0.1123,\n",
      "           -0.1260],\n",
      "          [ 0.2021,  0.5898,  0.1006, -0.1357, -1.0859,  0.1670, -0.8555,\n",
      "           -0.4785],\n",
      "          [ 0.1138, -0.8359, -0.1167, -0.1963,  0.5742,  0.5938,  0.4629,\n",
      "            0.6641]],\n",
      "\n",
      "         [[ 0.6992, -0.1670, -0.7812,  0.8555, -0.3320,  0.0031,  0.9609,\n",
      "           -0.3828],\n",
      "          [ 1.2578,  0.6758, -0.7930, -0.2227, -0.5156, -0.4609, -0.6016,\n",
      "            0.3633],\n",
      "          [-0.5859, -0.2871,  1.0156, -0.3594,  0.7266,  0.1943,  0.2197,\n",
      "            0.0284]],\n",
      "\n",
      "         [[-0.3770, -0.3398,  0.4258,  0.2930, -0.7422, -1.0000,  0.7461,\n",
      "            0.0771],\n",
      "          [-0.1523,  0.3828, -0.5195,  0.0082,  0.5664, -0.7031, -0.3691,\n",
      "            0.6602],\n",
      "          [ 0.3750, -0.1157, -0.1748, -0.6250,  0.4316,  0.8047, -0.0613,\n",
      "           -0.9688]],\n",
      "\n",
      "         [[-0.0181, -0.2344, -0.2471, -0.0569,  0.9062, -0.1768, -0.9102,\n",
      "            0.6523],\n",
      "          [ 0.5000, -0.5508, -0.6562,  0.5664,  0.8945,  0.1543, -0.9961,\n",
      "           -0.8633],\n",
      "          [-0.8594,  1.0000,  0.8125, -0.9766, -0.8477, -0.1484,  1.0391,\n",
      "           -0.2061]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.9688, -0.0645,  0.8477, -0.6836, -0.1641, -0.9688,  0.0457,\n",
      "           0.5859,  0.1167, -0.6172,  0.4277,  0.3418, -0.7891, -0.3848,\n",
      "           1.0391, -0.2402,  0.1973, -0.1670, -0.5078, -0.5078, -0.7969,\n",
      "          -0.1602,  0.4570,  0.2715, -1.2812,  0.6406, -0.7969, -0.1602,\n",
      "           0.2500,  0.9375, -0.1924,  0.6172],\n",
      "         [-0.2598,  0.0762, -0.3027,  0.3672,  0.6758, -0.1245,  0.8359,\n",
      "          -0.3926, -0.4727, -0.0928,  0.0444,  0.0391, -0.4160, -0.5820,\n",
      "          -0.1089, -0.0461,  0.4316,  0.5547, -0.1787, -0.3594,  0.2354,\n",
      "          -1.2109,  0.1611,  0.2480, -1.2734, -0.7617, -0.5664,  0.1768,\n",
      "           0.6523,  0.2100, -0.6836,  0.5391],\n",
      "         [ 0.2285, -0.9297,  0.9219, -0.1377, -0.7969, -0.2207, -0.9766,\n",
      "           0.1875,  0.6367, -0.1074,  0.4609, -0.8125, -0.0193,  0.2285,\n",
      "           1.0312, -0.6328, -0.6094, -0.5859,  0.2656, -0.1641, -1.1641,\n",
      "           0.7617,  0.3359, -0.2637,  0.1709,  0.9023, -0.0532,  0.2295,\n",
      "          -0.7383,  0.1318,  0.7383,  0.2129]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.9688, -0.0645,  0.8477, -0.6836, -0.1641, -0.9688,  0.0457,\n",
      "            0.5859],\n",
      "          [ 0.1167, -0.6172,  0.4277,  0.3418, -0.7891, -0.3848,  1.0391,\n",
      "           -0.2402],\n",
      "          [ 0.1973, -0.1670, -0.5078, -0.5078, -0.7969, -0.1602,  0.4570,\n",
      "            0.2715],\n",
      "          [-1.2812,  0.6406, -0.7969, -0.1602,  0.2500,  0.9375, -0.1924,\n",
      "            0.6172]],\n",
      "\n",
      "         [[-0.2598,  0.0762, -0.3027,  0.3672,  0.6758, -0.1245,  0.8359,\n",
      "           -0.3926],\n",
      "          [-0.4727, -0.0928,  0.0444,  0.0391, -0.4160, -0.5820, -0.1089,\n",
      "           -0.0461],\n",
      "          [ 0.4316,  0.5547, -0.1787, -0.3594,  0.2354, -1.2109,  0.1611,\n",
      "            0.2480],\n",
      "          [-1.2734, -0.7617, -0.5664,  0.1768,  0.6523,  0.2100, -0.6836,\n",
      "            0.5391]],\n",
      "\n",
      "         [[ 0.2285, -0.9297,  0.9219, -0.1377, -0.7969, -0.2207, -0.9766,\n",
      "            0.1875],\n",
      "          [ 0.6367, -0.1074,  0.4609, -0.8125, -0.0193,  0.2285,  1.0312,\n",
      "           -0.6328],\n",
      "          [-0.6094, -0.5859,  0.2656, -0.1641, -1.1641,  0.7617,  0.3359,\n",
      "           -0.2637],\n",
      "          [ 0.1709,  0.9023, -0.0532,  0.2295, -0.7383,  0.1318,  0.7383,\n",
      "            0.2129]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.9688, -0.0645,  0.8477, -0.6836, -0.1641, -0.9688,  0.0457,\n",
      "            0.5859],\n",
      "          [-0.2598,  0.0762, -0.3027,  0.3672,  0.6758, -0.1245,  0.8359,\n",
      "           -0.3926],\n",
      "          [ 0.2285, -0.9297,  0.9219, -0.1377, -0.7969, -0.2207, -0.9766,\n",
      "            0.1875]],\n",
      "\n",
      "         [[ 0.1167, -0.6172,  0.4277,  0.3418, -0.7891, -0.3848,  1.0391,\n",
      "           -0.2402],\n",
      "          [-0.4727, -0.0928,  0.0444,  0.0391, -0.4160, -0.5820, -0.1089,\n",
      "           -0.0461],\n",
      "          [ 0.6367, -0.1074,  0.4609, -0.8125, -0.0193,  0.2285,  1.0312,\n",
      "           -0.6328]],\n",
      "\n",
      "         [[ 0.1973, -0.1670, -0.5078, -0.5078, -0.7969, -0.1602,  0.4570,\n",
      "            0.2715],\n",
      "          [ 0.4316,  0.5547, -0.1787, -0.3594,  0.2354, -1.2109,  0.1611,\n",
      "            0.2480],\n",
      "          [-0.6094, -0.5859,  0.2656, -0.1641, -1.1641,  0.7617,  0.3359,\n",
      "           -0.2637]],\n",
      "\n",
      "         [[-1.2812,  0.6406, -0.7969, -0.1602,  0.2500,  0.9375, -0.1924,\n",
      "            0.6172],\n",
      "          [-1.2734, -0.7617, -0.5664,  0.1768,  0.6523,  0.2100, -0.6836,\n",
      "            0.5391],\n",
      "          [ 0.1709,  0.9023, -0.0532,  0.2295, -0.7383,  0.1318,  0.7383,\n",
      "            0.2129]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.1943, -0.6992, -1.1484, -0.0957,  0.8281, -0.0139, -0.6562,\n",
      "           0.0108,  0.2676,  0.0732, -0.0913, -0.6875, -0.7461, -0.0065,\n",
      "           0.5234, -0.0134,  0.2539,  0.5508,  1.1953,  0.1963,  0.7578,\n",
      "          -0.6406, -0.6484, -0.4668,  0.2871,  0.2969, -0.4043,  0.6523,\n",
      "          -0.0366,  0.1855, -0.7461, -0.4805],\n",
      "         [ 0.8086,  0.2734,  0.0811,  0.3633, -0.0840, -0.6797,  0.0962,\n",
      "          -0.4531,  0.0913, -0.3691, -0.3301,  0.5156,  0.8711, -0.1533,\n",
      "          -1.5781,  0.3477, -1.1250, -0.6992, -0.5898,  1.0469,  0.4238,\n",
      "           0.7305,  0.2402, -0.6797,  0.4453,  0.0327, -0.3516,  0.0474,\n",
      "           0.2070,  0.0752, -0.1299, -0.0850],\n",
      "         [-0.7188,  0.1807,  0.2295, -0.6758, -0.0491,  0.2812,  0.2793,\n",
      "           0.5977, -0.1338,  0.4531, -0.3340,  0.5898, -0.1709,  0.1885,\n",
      "          -0.5898, -0.8164, -0.1738,  0.0216,  0.0048,  0.0918, -0.9023,\n",
      "          -0.3633,  0.4355,  0.8672, -0.6562,  0.3477,  0.9844, -0.4316,\n",
      "          -1.1406, -0.2656,  0.0537, -0.3438]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.1943, -0.6992, -1.1484, -0.0957,  0.8281, -0.0139, -0.6562,\n",
      "            0.0108],\n",
      "          [ 0.2676,  0.0732, -0.0913, -0.6875, -0.7461, -0.0065,  0.5234,\n",
      "           -0.0134],\n",
      "          [ 0.2539,  0.5508,  1.1953,  0.1963,  0.7578, -0.6406, -0.6484,\n",
      "           -0.4668],\n",
      "          [ 0.2871,  0.2969, -0.4043,  0.6523, -0.0366,  0.1855, -0.7461,\n",
      "           -0.4805]],\n",
      "\n",
      "         [[ 0.8086,  0.2734,  0.0811,  0.3633, -0.0840, -0.6797,  0.0962,\n",
      "           -0.4531],\n",
      "          [ 0.0913, -0.3691, -0.3301,  0.5156,  0.8711, -0.1533, -1.5781,\n",
      "            0.3477],\n",
      "          [-1.1250, -0.6992, -0.5898,  1.0469,  0.4238,  0.7305,  0.2402,\n",
      "           -0.6797],\n",
      "          [ 0.4453,  0.0327, -0.3516,  0.0474,  0.2070,  0.0752, -0.1299,\n",
      "           -0.0850]],\n",
      "\n",
      "         [[-0.7188,  0.1807,  0.2295, -0.6758, -0.0491,  0.2812,  0.2793,\n",
      "            0.5977],\n",
      "          [-0.1338,  0.4531, -0.3340,  0.5898, -0.1709,  0.1885, -0.5898,\n",
      "           -0.8164],\n",
      "          [-0.1738,  0.0216,  0.0048,  0.0918, -0.9023, -0.3633,  0.4355,\n",
      "            0.8672],\n",
      "          [-0.6562,  0.3477,  0.9844, -0.4316, -1.1406, -0.2656,  0.0537,\n",
      "           -0.3438]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.1943, -0.6992, -1.1484, -0.0957,  0.8281, -0.0139, -0.6562,\n",
      "            0.0108],\n",
      "          [ 0.8086,  0.2734,  0.0811,  0.3633, -0.0840, -0.6797,  0.0962,\n",
      "           -0.4531],\n",
      "          [-0.7188,  0.1807,  0.2295, -0.6758, -0.0491,  0.2812,  0.2793,\n",
      "            0.5977]],\n",
      "\n",
      "         [[ 0.2676,  0.0732, -0.0913, -0.6875, -0.7461, -0.0065,  0.5234,\n",
      "           -0.0134],\n",
      "          [ 0.0913, -0.3691, -0.3301,  0.5156,  0.8711, -0.1533, -1.5781,\n",
      "            0.3477],\n",
      "          [-0.1338,  0.4531, -0.3340,  0.5898, -0.1709,  0.1885, -0.5898,\n",
      "           -0.8164]],\n",
      "\n",
      "         [[ 0.2539,  0.5508,  1.1953,  0.1963,  0.7578, -0.6406, -0.6484,\n",
      "           -0.4668],\n",
      "          [-1.1250, -0.6992, -0.5898,  1.0469,  0.4238,  0.7305,  0.2402,\n",
      "           -0.6797],\n",
      "          [-0.1738,  0.0216,  0.0048,  0.0918, -0.9023, -0.3633,  0.4355,\n",
      "            0.8672]],\n",
      "\n",
      "         [[ 0.2871,  0.2969, -0.4043,  0.6523, -0.0366,  0.1855, -0.7461,\n",
      "           -0.4805],\n",
      "          [ 0.4453,  0.0327, -0.3516,  0.0474,  0.2070,  0.0752, -0.1299,\n",
      "           -0.0850],\n",
      "          [-0.6562,  0.3477,  0.9844, -0.4316, -1.1406, -0.2656,  0.0537,\n",
      "           -0.3438]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.2559, -0.0493,  0.2734, -0.6289, -0.4844,  0.4922,  0.0962,\n",
      "          -0.9258, -0.6172, -0.8555,  0.1299, -0.6758,  0.9336, -0.6094,\n",
      "          -0.2197, -0.1514, -0.4570, -0.2871, -0.2656, -0.3105,  0.4453,\n",
      "           0.3281,  0.0811, -0.7617,  0.1699, -0.8203,  0.3613,  0.5117,\n",
      "          -0.5859, -0.2100,  0.5781, -0.3730],\n",
      "         [ 0.5664,  0.1025,  1.1406, -0.5898,  0.3965, -0.8789, -0.0361,\n",
      "           0.8945, -0.4668, -0.2090,  1.1016, -0.5234, -0.5195, -0.1992,\n",
      "          -0.0498, -0.1777, -0.3555, -0.3008,  0.4160, -0.5625, -0.4297,\n",
      "           0.1475, -0.0123,  0.0571, -0.3047,  0.4922, -0.3574, -0.0684,\n",
      "           0.7344, -0.5234, -0.8008, -0.8984],\n",
      "         [-0.5742,  0.4629,  0.3223, -0.1689, -0.6406,  0.1318,  0.8750,\n",
      "          -0.7578,  0.8398, -0.3906,  0.4629,  0.6602,  0.9062,  0.1367,\n",
      "           0.8242,  1.0547, -0.2061, -0.3730,  0.3594,  0.5820, -0.1494,\n",
      "          -1.1172,  0.5625,  0.1416, -0.9375, -0.4355,  1.3828,  0.3340,\n",
      "          -0.7500,  0.2676, -0.0564,  0.2275]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.2559, -0.0493,  0.2734, -0.6289, -0.4844,  0.4922,  0.0962,\n",
      "           -0.9258],\n",
      "          [-0.6172, -0.8555,  0.1299, -0.6758,  0.9336, -0.6094, -0.2197,\n",
      "           -0.1514],\n",
      "          [-0.4570, -0.2871, -0.2656, -0.3105,  0.4453,  0.3281,  0.0811,\n",
      "           -0.7617],\n",
      "          [ 0.1699, -0.8203,  0.3613,  0.5117, -0.5859, -0.2100,  0.5781,\n",
      "           -0.3730]],\n",
      "\n",
      "         [[ 0.5664,  0.1025,  1.1406, -0.5898,  0.3965, -0.8789, -0.0361,\n",
      "            0.8945],\n",
      "          [-0.4668, -0.2090,  1.1016, -0.5234, -0.5195, -0.1992, -0.0498,\n",
      "           -0.1777],\n",
      "          [-0.3555, -0.3008,  0.4160, -0.5625, -0.4297,  0.1475, -0.0123,\n",
      "            0.0571],\n",
      "          [-0.3047,  0.4922, -0.3574, -0.0684,  0.7344, -0.5234, -0.8008,\n",
      "           -0.8984]],\n",
      "\n",
      "         [[-0.5742,  0.4629,  0.3223, -0.1689, -0.6406,  0.1318,  0.8750,\n",
      "           -0.7578],\n",
      "          [ 0.8398, -0.3906,  0.4629,  0.6602,  0.9062,  0.1367,  0.8242,\n",
      "            1.0547],\n",
      "          [-0.2061, -0.3730,  0.3594,  0.5820, -0.1494, -1.1172,  0.5625,\n",
      "            0.1416],\n",
      "          [-0.9375, -0.4355,  1.3828,  0.3340, -0.7500,  0.2676, -0.0564,\n",
      "            0.2275]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.2559, -0.0493,  0.2734, -0.6289, -0.4844,  0.4922,  0.0962,\n",
      "           -0.9258],\n",
      "          [ 0.5664,  0.1025,  1.1406, -0.5898,  0.3965, -0.8789, -0.0361,\n",
      "            0.8945],\n",
      "          [-0.5742,  0.4629,  0.3223, -0.1689, -0.6406,  0.1318,  0.8750,\n",
      "           -0.7578]],\n",
      "\n",
      "         [[-0.6172, -0.8555,  0.1299, -0.6758,  0.9336, -0.6094, -0.2197,\n",
      "           -0.1514],\n",
      "          [-0.4668, -0.2090,  1.1016, -0.5234, -0.5195, -0.1992, -0.0498,\n",
      "           -0.1777],\n",
      "          [ 0.8398, -0.3906,  0.4629,  0.6602,  0.9062,  0.1367,  0.8242,\n",
      "            1.0547]],\n",
      "\n",
      "         [[-0.4570, -0.2871, -0.2656, -0.3105,  0.4453,  0.3281,  0.0811,\n",
      "           -0.7617],\n",
      "          [-0.3555, -0.3008,  0.4160, -0.5625, -0.4297,  0.1475, -0.0123,\n",
      "            0.0571],\n",
      "          [-0.2061, -0.3730,  0.3594,  0.5820, -0.1494, -1.1172,  0.5625,\n",
      "            0.1416]],\n",
      "\n",
      "         [[ 0.1699, -0.8203,  0.3613,  0.5117, -0.5859, -0.2100,  0.5781,\n",
      "           -0.3730],\n",
      "          [-0.3047,  0.4922, -0.3574, -0.0684,  0.7344, -0.5234, -0.8008,\n",
      "           -0.8984],\n",
      "          [-0.9375, -0.4355,  1.3828,  0.3340, -0.7500,  0.2676, -0.0564,\n",
      "            0.2275]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.5078,  0.2676, -0.2871, -0.1680,  0.0308, -0.0342, -0.5898,\n",
      "          -0.5195,  0.2451, -0.0099,  0.7930,  0.2695,  0.7422, -0.0449,\n",
      "           0.0162, -0.9961,  0.1660,  0.8789, -0.3496, -0.6719, -0.1436,\n",
      "          -0.4824, -0.3750,  0.9688,  0.2578,  0.5625,  0.9961, -1.1250,\n",
      "          -0.8242,  0.6602, -0.5273,  0.3320],\n",
      "         [ 0.1953,  0.4023, -0.6641,  0.1680, -1.4766,  0.4258, -0.0623,\n",
      "          -0.2217,  0.1699, -0.4102, -0.2676, -1.0234,  0.2852, -0.4570,\n",
      "           0.9609,  0.1855,  0.3457,  0.2070,  0.2617, -0.3105,  0.3164,\n",
      "          -0.3418,  0.0334, -0.0352,  0.0879,  0.4707,  0.6172, -0.4473,\n",
      "           0.5938, -0.1187, -0.7930,  0.7969],\n",
      "         [ 0.4375,  0.8477, -0.2178, -0.0718, -0.8281, -0.6758,  0.1807,\n",
      "          -0.1152, -0.3320,  0.3867,  1.1484, -0.6094,  0.9492,  0.0762,\n",
      "           0.3652, -0.2031,  0.6055,  0.3379,  0.3301, -0.5938, -0.0500,\n",
      "          -0.6289, -0.0084,  1.2578,  0.5273,  0.2988,  0.1680, -0.8828,\n",
      "          -0.5820,  0.9297, -0.4473, -0.2480]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.5078,  0.2676, -0.2871, -0.1680,  0.0308, -0.0342, -0.5898,\n",
      "           -0.5195],\n",
      "          [ 0.2451, -0.0099,  0.7930,  0.2695,  0.7422, -0.0449,  0.0162,\n",
      "           -0.9961],\n",
      "          [ 0.1660,  0.8789, -0.3496, -0.6719, -0.1436, -0.4824, -0.3750,\n",
      "            0.9688],\n",
      "          [ 0.2578,  0.5625,  0.9961, -1.1250, -0.8242,  0.6602, -0.5273,\n",
      "            0.3320]],\n",
      "\n",
      "         [[ 0.1953,  0.4023, -0.6641,  0.1680, -1.4766,  0.4258, -0.0623,\n",
      "           -0.2217],\n",
      "          [ 0.1699, -0.4102, -0.2676, -1.0234,  0.2852, -0.4570,  0.9609,\n",
      "            0.1855],\n",
      "          [ 0.3457,  0.2070,  0.2617, -0.3105,  0.3164, -0.3418,  0.0334,\n",
      "           -0.0352],\n",
      "          [ 0.0879,  0.4707,  0.6172, -0.4473,  0.5938, -0.1187, -0.7930,\n",
      "            0.7969]],\n",
      "\n",
      "         [[ 0.4375,  0.8477, -0.2178, -0.0718, -0.8281, -0.6758,  0.1807,\n",
      "           -0.1152],\n",
      "          [-0.3320,  0.3867,  1.1484, -0.6094,  0.9492,  0.0762,  0.3652,\n",
      "           -0.2031],\n",
      "          [ 0.6055,  0.3379,  0.3301, -0.5938, -0.0500, -0.6289, -0.0084,\n",
      "            1.2578],\n",
      "          [ 0.5273,  0.2988,  0.1680, -0.8828, -0.5820,  0.9297, -0.4473,\n",
      "           -0.2480]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.5078,  0.2676, -0.2871, -0.1680,  0.0308, -0.0342, -0.5898,\n",
      "           -0.5195],\n",
      "          [ 0.1953,  0.4023, -0.6641,  0.1680, -1.4766,  0.4258, -0.0623,\n",
      "           -0.2217],\n",
      "          [ 0.4375,  0.8477, -0.2178, -0.0718, -0.8281, -0.6758,  0.1807,\n",
      "           -0.1152]],\n",
      "\n",
      "         [[ 0.2451, -0.0099,  0.7930,  0.2695,  0.7422, -0.0449,  0.0162,\n",
      "           -0.9961],\n",
      "          [ 0.1699, -0.4102, -0.2676, -1.0234,  0.2852, -0.4570,  0.9609,\n",
      "            0.1855],\n",
      "          [-0.3320,  0.3867,  1.1484, -0.6094,  0.9492,  0.0762,  0.3652,\n",
      "           -0.2031]],\n",
      "\n",
      "         [[ 0.1660,  0.8789, -0.3496, -0.6719, -0.1436, -0.4824, -0.3750,\n",
      "            0.9688],\n",
      "          [ 0.3457,  0.2070,  0.2617, -0.3105,  0.3164, -0.3418,  0.0334,\n",
      "           -0.0352],\n",
      "          [ 0.6055,  0.3379,  0.3301, -0.5938, -0.0500, -0.6289, -0.0084,\n",
      "            1.2578]],\n",
      "\n",
      "         [[ 0.2578,  0.5625,  0.9961, -1.1250, -0.8242,  0.6602, -0.5273,\n",
      "            0.3320],\n",
      "          [ 0.0879,  0.4707,  0.6172, -0.4473,  0.5938, -0.1187, -0.7930,\n",
      "            0.7969],\n",
      "          [ 0.5273,  0.2988,  0.1680, -0.8828, -0.5820,  0.9297, -0.4473,\n",
      "           -0.2480]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 1.1094,  0.0608,  0.8945,  0.4512, -1.0703, -0.7969, -0.4336,\n",
      "           0.5234, -0.5625, -0.1299, -0.2305, -0.5195, -0.2852,  1.3281,\n",
      "           0.1768, -0.5586,  0.2539, -0.1118, -0.0027, -0.5547,  0.5508,\n",
      "          -0.1250, -0.4336,  0.9258,  0.2812,  0.3359, -0.7227, -0.9727,\n",
      "          -0.0684,  0.4922, -0.8438,  0.4004],\n",
      "         [ 0.2432,  0.0786, -0.0571, -0.5664, -0.1328, -0.1533,  0.0732,\n",
      "           0.0554, -1.1875, -0.3164, -0.8633,  0.3496, -0.3965,  0.2949,\n",
      "           0.0618, -0.3984,  0.7188,  1.3750, -0.2891,  0.3418, -0.3008,\n",
      "          -0.8086, -0.4160,  0.7891,  0.5234,  0.4727, -0.4062,  0.1206,\n",
      "           0.8906, -0.5391, -0.2119,  0.1445],\n",
      "         [ 0.6445, -0.2373,  0.5547, -0.1074, -0.5273, -0.7578, -0.0500,\n",
      "           0.3750, -1.4141, -0.3262, -0.6758,  0.0708, -0.2910,  1.0234,\n",
      "           0.0767, -0.9492,  0.8047,  0.9141, -0.3125, -0.2695,  0.2080,\n",
      "          -0.7305, -0.8789,  1.3438,  0.6797,  0.5977, -0.9023, -0.2266,\n",
      "           0.9414, -0.1016, -0.8867,  0.6953]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 1.1094,  0.0608,  0.8945,  0.4512, -1.0703, -0.7969, -0.4336,\n",
      "            0.5234],\n",
      "          [-0.5625, -0.1299, -0.2305, -0.5195, -0.2852,  1.3281,  0.1768,\n",
      "           -0.5586],\n",
      "          [ 0.2539, -0.1118, -0.0027, -0.5547,  0.5508, -0.1250, -0.4336,\n",
      "            0.9258],\n",
      "          [ 0.2812,  0.3359, -0.7227, -0.9727, -0.0684,  0.4922, -0.8438,\n",
      "            0.4004]],\n",
      "\n",
      "         [[ 0.2432,  0.0786, -0.0571, -0.5664, -0.1328, -0.1533,  0.0732,\n",
      "            0.0554],\n",
      "          [-1.1875, -0.3164, -0.8633,  0.3496, -0.3965,  0.2949,  0.0618,\n",
      "           -0.3984],\n",
      "          [ 0.7188,  1.3750, -0.2891,  0.3418, -0.3008, -0.8086, -0.4160,\n",
      "            0.7891],\n",
      "          [ 0.5234,  0.4727, -0.4062,  0.1206,  0.8906, -0.5391, -0.2119,\n",
      "            0.1445]],\n",
      "\n",
      "         [[ 0.6445, -0.2373,  0.5547, -0.1074, -0.5273, -0.7578, -0.0500,\n",
      "            0.3750],\n",
      "          [-1.4141, -0.3262, -0.6758,  0.0708, -0.2910,  1.0234,  0.0767,\n",
      "           -0.9492],\n",
      "          [ 0.8047,  0.9141, -0.3125, -0.2695,  0.2080, -0.7305, -0.8789,\n",
      "            1.3438],\n",
      "          [ 0.6797,  0.5977, -0.9023, -0.2266,  0.9414, -0.1016, -0.8867,\n",
      "            0.6953]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 1.1094,  0.0608,  0.8945,  0.4512, -1.0703, -0.7969, -0.4336,\n",
      "            0.5234],\n",
      "          [ 0.2432,  0.0786, -0.0571, -0.5664, -0.1328, -0.1533,  0.0732,\n",
      "            0.0554],\n",
      "          [ 0.6445, -0.2373,  0.5547, -0.1074, -0.5273, -0.7578, -0.0500,\n",
      "            0.3750]],\n",
      "\n",
      "         [[-0.5625, -0.1299, -0.2305, -0.5195, -0.2852,  1.3281,  0.1768,\n",
      "           -0.5586],\n",
      "          [-1.1875, -0.3164, -0.8633,  0.3496, -0.3965,  0.2949,  0.0618,\n",
      "           -0.3984],\n",
      "          [-1.4141, -0.3262, -0.6758,  0.0708, -0.2910,  1.0234,  0.0767,\n",
      "           -0.9492]],\n",
      "\n",
      "         [[ 0.2539, -0.1118, -0.0027, -0.5547,  0.5508, -0.1250, -0.4336,\n",
      "            0.9258],\n",
      "          [ 0.7188,  1.3750, -0.2891,  0.3418, -0.3008, -0.8086, -0.4160,\n",
      "            0.7891],\n",
      "          [ 0.8047,  0.9141, -0.3125, -0.2695,  0.2080, -0.7305, -0.8789,\n",
      "            1.3438]],\n",
      "\n",
      "         [[ 0.2812,  0.3359, -0.7227, -0.9727, -0.0684,  0.4922, -0.8438,\n",
      "            0.4004],\n",
      "          [ 0.5234,  0.4727, -0.4062,  0.1206,  0.8906, -0.5391, -0.2119,\n",
      "            0.1445],\n",
      "          [ 0.6797,  0.5977, -0.9023, -0.2266,  0.9414, -0.1016, -0.8867,\n",
      "            0.6953]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.9844,  0.7070, -0.3281,  0.9336, -0.2451,  0.9766,  1.2422,\n",
      "          -0.0713, -0.2305,  0.1729,  0.2793,  0.3906,  0.1699,  0.2441,\n",
      "          -0.5078, -0.2246,  0.3945, -0.6641,  0.1982,  0.3496, -0.5508,\n",
      "          -0.5469,  0.5391, -0.7695,  0.7305, -0.1060, -0.1699, -0.0781,\n",
      "           0.1328,  0.9922, -0.4883, -1.1328],\n",
      "         [ 0.0247,  0.2793, -0.8359,  0.3086, -0.0879, -0.3047,  0.6914,\n",
      "           0.5664,  0.6328,  0.4707, -0.4004,  0.6133,  0.0791,  0.9297,\n",
      "          -1.1484,  0.7500, -0.0967,  0.5352, -0.2227, -0.6602, -0.3828,\n",
      "          -0.8867,  0.2715,  0.6367,  0.2373, -0.4980,  0.1768, -0.3379,\n",
      "          -0.1602,  0.0152, -0.5469, -0.4980],\n",
      "         [ 0.5469,  0.4805, -0.3457,  0.4121, -0.2637,  0.1953,  1.2578,\n",
      "           0.2002,  0.1797,  0.2910,  0.1846,  0.9062,  0.0459,  0.7969,\n",
      "          -1.1250,  0.3906, -0.0640,  0.0723,  0.2266,  0.0510, -0.7500,\n",
      "          -1.0469,  0.6484,  0.1240,  0.3848, -0.5938, -0.2021,  0.0165,\n",
      "          -0.1553,  0.4395, -0.3008, -0.7500]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.9844,  0.7070, -0.3281,  0.9336, -0.2451,  0.9766,  1.2422,\n",
      "           -0.0713],\n",
      "          [-0.2305,  0.1729,  0.2793,  0.3906,  0.1699,  0.2441, -0.5078,\n",
      "           -0.2246],\n",
      "          [ 0.3945, -0.6641,  0.1982,  0.3496, -0.5508, -0.5469,  0.5391,\n",
      "           -0.7695],\n",
      "          [ 0.7305, -0.1060, -0.1699, -0.0781,  0.1328,  0.9922, -0.4883,\n",
      "           -1.1328]],\n",
      "\n",
      "         [[ 0.0247,  0.2793, -0.8359,  0.3086, -0.0879, -0.3047,  0.6914,\n",
      "            0.5664],\n",
      "          [ 0.6328,  0.4707, -0.4004,  0.6133,  0.0791,  0.9297, -1.1484,\n",
      "            0.7500],\n",
      "          [-0.0967,  0.5352, -0.2227, -0.6602, -0.3828, -0.8867,  0.2715,\n",
      "            0.6367],\n",
      "          [ 0.2373, -0.4980,  0.1768, -0.3379, -0.1602,  0.0152, -0.5469,\n",
      "           -0.4980]],\n",
      "\n",
      "         [[ 0.5469,  0.4805, -0.3457,  0.4121, -0.2637,  0.1953,  1.2578,\n",
      "            0.2002],\n",
      "          [ 0.1797,  0.2910,  0.1846,  0.9062,  0.0459,  0.7969, -1.1250,\n",
      "            0.3906],\n",
      "          [-0.0640,  0.0723,  0.2266,  0.0510, -0.7500, -1.0469,  0.6484,\n",
      "            0.1240],\n",
      "          [ 0.3848, -0.5938, -0.2021,  0.0165, -0.1553,  0.4395, -0.3008,\n",
      "           -0.7500]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.9844,  0.7070, -0.3281,  0.9336, -0.2451,  0.9766,  1.2422,\n",
      "           -0.0713],\n",
      "          [ 0.0247,  0.2793, -0.8359,  0.3086, -0.0879, -0.3047,  0.6914,\n",
      "            0.5664],\n",
      "          [ 0.5469,  0.4805, -0.3457,  0.4121, -0.2637,  0.1953,  1.2578,\n",
      "            0.2002]],\n",
      "\n",
      "         [[-0.2305,  0.1729,  0.2793,  0.3906,  0.1699,  0.2441, -0.5078,\n",
      "           -0.2246],\n",
      "          [ 0.6328,  0.4707, -0.4004,  0.6133,  0.0791,  0.9297, -1.1484,\n",
      "            0.7500],\n",
      "          [ 0.1797,  0.2910,  0.1846,  0.9062,  0.0459,  0.7969, -1.1250,\n",
      "            0.3906]],\n",
      "\n",
      "         [[ 0.3945, -0.6641,  0.1982,  0.3496, -0.5508, -0.5469,  0.5391,\n",
      "           -0.7695],\n",
      "          [-0.0967,  0.5352, -0.2227, -0.6602, -0.3828, -0.8867,  0.2715,\n",
      "            0.6367],\n",
      "          [-0.0640,  0.0723,  0.2266,  0.0510, -0.7500, -1.0469,  0.6484,\n",
      "            0.1240]],\n",
      "\n",
      "         [[ 0.7305, -0.1060, -0.1699, -0.0781,  0.1328,  0.9922, -0.4883,\n",
      "           -1.1328],\n",
      "          [ 0.2373, -0.4980,  0.1768, -0.3379, -0.1602,  0.0152, -0.5469,\n",
      "           -0.4980],\n",
      "          [ 0.3848, -0.5938, -0.2021,  0.0165, -0.1553,  0.4395, -0.3008,\n",
      "           -0.7500]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 1.0156,  0.7578,  0.0237,  0.2578, -0.9297, -0.3164, -0.3672,\n",
      "          -0.6641, -0.4883, -0.0571,  0.0491,  0.3340, -0.9375,  0.2949,\n",
      "           0.9609,  0.1250,  0.2969,  0.9727,  0.3574,  0.9258,  0.3086,\n",
      "           0.0461,  1.1250, -0.4668,  0.2344, -0.2305, -0.7617,  0.5312,\n",
      "           0.8125,  0.4668, -0.1738, -1.1484],\n",
      "         [ 0.1543, -0.1943,  0.6758, -0.7891,  0.0479,  0.0679,  0.0256,\n",
      "           0.0952, -0.1465,  0.1904, -0.2500,  0.2969, -0.3750,  1.5938,\n",
      "           0.5391,  1.0938, -0.7461, -0.0045,  0.8086, -0.0664, -0.1543,\n",
      "          -0.4297,  0.7500, -0.8125,  0.5078,  0.9023,  0.2988,  0.9883,\n",
      "          -0.1196, -0.6016, -1.0547, -0.5938],\n",
      "         [ 1.0625,  0.7461, -0.0300,  0.2500, -0.5586, -0.1611,  0.0199,\n",
      "          -0.5078, -0.2871, -0.0564,  0.2598,  0.3164, -0.8320,  0.7695,\n",
      "           0.8555,  0.3438, -0.1553,  0.8945,  0.4277,  0.7812,  0.1260,\n",
      "           0.1318,  0.7852, -0.7773,  0.2012,  0.1543, -0.7734,  0.7500,\n",
      "           0.8516,  0.4414, -0.5469, -1.0781]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 1.0156,  0.7578,  0.0237,  0.2578, -0.9297, -0.3164, -0.3672,\n",
      "           -0.6641],\n",
      "          [-0.4883, -0.0571,  0.0491,  0.3340, -0.9375,  0.2949,  0.9609,\n",
      "            0.1250],\n",
      "          [ 0.2969,  0.9727,  0.3574,  0.9258,  0.3086,  0.0461,  1.1250,\n",
      "           -0.4668],\n",
      "          [ 0.2344, -0.2305, -0.7617,  0.5312,  0.8125,  0.4668, -0.1738,\n",
      "           -1.1484]],\n",
      "\n",
      "         [[ 0.1543, -0.1943,  0.6758, -0.7891,  0.0479,  0.0679,  0.0256,\n",
      "            0.0952],\n",
      "          [-0.1465,  0.1904, -0.2500,  0.2969, -0.3750,  1.5938,  0.5391,\n",
      "            1.0938],\n",
      "          [-0.7461, -0.0045,  0.8086, -0.0664, -0.1543, -0.4297,  0.7500,\n",
      "           -0.8125],\n",
      "          [ 0.5078,  0.9023,  0.2988,  0.9883, -0.1196, -0.6016, -1.0547,\n",
      "           -0.5938]],\n",
      "\n",
      "         [[ 1.0625,  0.7461, -0.0300,  0.2500, -0.5586, -0.1611,  0.0199,\n",
      "           -0.5078],\n",
      "          [-0.2871, -0.0564,  0.2598,  0.3164, -0.8320,  0.7695,  0.8555,\n",
      "            0.3438],\n",
      "          [-0.1553,  0.8945,  0.4277,  0.7812,  0.1260,  0.1318,  0.7852,\n",
      "           -0.7773],\n",
      "          [ 0.2012,  0.1543, -0.7734,  0.7500,  0.8516,  0.4414, -0.5469,\n",
      "           -1.0781]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 1.0156,  0.7578,  0.0237,  0.2578, -0.9297, -0.3164, -0.3672,\n",
      "           -0.6641],\n",
      "          [ 0.1543, -0.1943,  0.6758, -0.7891,  0.0479,  0.0679,  0.0256,\n",
      "            0.0952],\n",
      "          [ 1.0625,  0.7461, -0.0300,  0.2500, -0.5586, -0.1611,  0.0199,\n",
      "           -0.5078]],\n",
      "\n",
      "         [[-0.4883, -0.0571,  0.0491,  0.3340, -0.9375,  0.2949,  0.9609,\n",
      "            0.1250],\n",
      "          [-0.1465,  0.1904, -0.2500,  0.2969, -0.3750,  1.5938,  0.5391,\n",
      "            1.0938],\n",
      "          [-0.2871, -0.0564,  0.2598,  0.3164, -0.8320,  0.7695,  0.8555,\n",
      "            0.3438]],\n",
      "\n",
      "         [[ 0.2969,  0.9727,  0.3574,  0.9258,  0.3086,  0.0461,  1.1250,\n",
      "           -0.4668],\n",
      "          [-0.7461, -0.0045,  0.8086, -0.0664, -0.1543, -0.4297,  0.7500,\n",
      "           -0.8125],\n",
      "          [-0.1553,  0.8945,  0.4277,  0.7812,  0.1260,  0.1318,  0.7852,\n",
      "           -0.7773]],\n",
      "\n",
      "         [[ 0.2344, -0.2305, -0.7617,  0.5312,  0.8125,  0.4668, -0.1738,\n",
      "           -1.1484],\n",
      "          [ 0.5078,  0.9023,  0.2988,  0.9883, -0.1196, -0.6016, -1.0547,\n",
      "           -0.5938],\n",
      "          [ 0.2012,  0.1543, -0.7734,  0.7500,  0.8516,  0.4414, -0.5469,\n",
      "           -1.0781]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.7227, -0.2383,  0.3555, -0.5312, -0.4961, -0.8086,  0.3320,\n",
      "           0.0417,  0.5664,  0.2363, -0.3262, -0.1699,  0.3047, -0.4766,\n",
      "          -0.4805,  0.3770, -0.3926,  0.3672,  0.1875,  0.1206, -0.0947,\n",
      "          -0.1992, -0.5117,  0.7344,  0.6133,  1.1484,  0.5625, -0.0181,\n",
      "           0.4336, -0.7227, -0.6445,  0.3633],\n",
      "         [ 0.1650,  0.6211, -0.1270,  0.0850, -0.3730, -0.8750, -0.3262,\n",
      "          -0.7891,  0.0378, -0.8555, -0.6641,  1.0078,  0.9062, -0.0884,\n",
      "           0.7422,  0.9531,  0.1006, -0.2256, -0.1533, -0.3926,  0.6172,\n",
      "          -0.3047, -0.7734,  0.5430,  0.7188,  0.4434,  0.0258,  0.0400,\n",
      "          -0.0356, -0.1787, -0.5391, -0.0270],\n",
      "         [-0.6484, -0.1494,  0.4141, -0.4551, -0.4785, -0.7422,  0.2637,\n",
      "          -0.0459,  0.5508,  0.1006, -0.4590, -0.0347,  0.4023, -0.5078,\n",
      "          -0.4121,  0.4160, -0.3711,  0.4492,  0.1602,  0.0400, -0.1113,\n",
      "          -0.1865, -0.6016,  0.7344,  0.6914,  1.0703,  0.6055, -0.0100,\n",
      "           0.3574, -0.7148, -0.6797,  0.2354]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.7227, -0.2383,  0.3555, -0.5312, -0.4961, -0.8086,  0.3320,\n",
      "            0.0417],\n",
      "          [ 0.5664,  0.2363, -0.3262, -0.1699,  0.3047, -0.4766, -0.4805,\n",
      "            0.3770],\n",
      "          [-0.3926,  0.3672,  0.1875,  0.1206, -0.0947, -0.1992, -0.5117,\n",
      "            0.7344],\n",
      "          [ 0.6133,  1.1484,  0.5625, -0.0181,  0.4336, -0.7227, -0.6445,\n",
      "            0.3633]],\n",
      "\n",
      "         [[ 0.1650,  0.6211, -0.1270,  0.0850, -0.3730, -0.8750, -0.3262,\n",
      "           -0.7891],\n",
      "          [ 0.0378, -0.8555, -0.6641,  1.0078,  0.9062, -0.0884,  0.7422,\n",
      "            0.9531],\n",
      "          [ 0.1006, -0.2256, -0.1533, -0.3926,  0.6172, -0.3047, -0.7734,\n",
      "            0.5430],\n",
      "          [ 0.7188,  0.4434,  0.0258,  0.0400, -0.0356, -0.1787, -0.5391,\n",
      "           -0.0270]],\n",
      "\n",
      "         [[-0.6484, -0.1494,  0.4141, -0.4551, -0.4785, -0.7422,  0.2637,\n",
      "           -0.0459],\n",
      "          [ 0.5508,  0.1006, -0.4590, -0.0347,  0.4023, -0.5078, -0.4121,\n",
      "            0.4160],\n",
      "          [-0.3711,  0.4492,  0.1602,  0.0400, -0.1113, -0.1865, -0.6016,\n",
      "            0.7344],\n",
      "          [ 0.6914,  1.0703,  0.6055, -0.0100,  0.3574, -0.7148, -0.6797,\n",
      "            0.2354]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.7227, -0.2383,  0.3555, -0.5312, -0.4961, -0.8086,  0.3320,\n",
      "            0.0417],\n",
      "          [ 0.1650,  0.6211, -0.1270,  0.0850, -0.3730, -0.8750, -0.3262,\n",
      "           -0.7891],\n",
      "          [-0.6484, -0.1494,  0.4141, -0.4551, -0.4785, -0.7422,  0.2637,\n",
      "           -0.0459]],\n",
      "\n",
      "         [[ 0.5664,  0.2363, -0.3262, -0.1699,  0.3047, -0.4766, -0.4805,\n",
      "            0.3770],\n",
      "          [ 0.0378, -0.8555, -0.6641,  1.0078,  0.9062, -0.0884,  0.7422,\n",
      "            0.9531],\n",
      "          [ 0.5508,  0.1006, -0.4590, -0.0347,  0.4023, -0.5078, -0.4121,\n",
      "            0.4160]],\n",
      "\n",
      "         [[-0.3926,  0.3672,  0.1875,  0.1206, -0.0947, -0.1992, -0.5117,\n",
      "            0.7344],\n",
      "          [ 0.1006, -0.2256, -0.1533, -0.3926,  0.6172, -0.3047, -0.7734,\n",
      "            0.5430],\n",
      "          [-0.3711,  0.4492,  0.1602,  0.0400, -0.1113, -0.1865, -0.6016,\n",
      "            0.7344]],\n",
      "\n",
      "         [[ 0.6133,  1.1484,  0.5625, -0.0181,  0.4336, -0.7227, -0.6445,\n",
      "            0.3633],\n",
      "          [ 0.7188,  0.4434,  0.0258,  0.0400, -0.0356, -0.1787, -0.5391,\n",
      "           -0.0270],\n",
      "          [ 0.6914,  1.0703,  0.6055, -0.0100,  0.3574, -0.7148, -0.6797,\n",
      "            0.2354]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.5117,  0.1846, -0.6523, -0.2910, -0.7578,  0.1934,  0.3516,\n",
      "          -0.6445,  0.4902,  1.0000, -0.5234,  0.9805,  0.2109, -0.9023,\n",
      "           0.5273,  0.6406,  0.6367, -0.4141, -0.1797,  0.3398, -0.0840,\n",
      "          -0.7656,  0.2832,  0.8242,  0.6875,  0.3906,  0.9141, -0.5234,\n",
      "          -0.6953, -0.5938, -0.9570, -1.1484],\n",
      "         [ 0.4629,  0.4746, -0.0928, -0.6172, -0.5078, -0.3711,  0.6289,\n",
      "          -0.7773,  1.0625,  0.9609, -0.3594,  0.6367,  0.4375, -0.1758,\n",
      "          -0.4805,  0.1592, -0.4629,  0.1157, -0.8945, -0.7188, -0.8438,\n",
      "          -0.1592,  0.5781,  0.9922,  0.0864, -0.8320,  0.5391, -0.5195,\n",
      "           0.4160,  0.4277, -0.3672, -0.7305],\n",
      "         [ 0.4824, -0.3125, -0.8242, -0.4238, -0.8555, -0.0688,  0.0564,\n",
      "          -0.5312,  0.7500,  0.8867, -0.8672,  0.7422,  0.5820, -0.4746,\n",
      "           0.4492,  0.6914,  0.3828, -0.6680, -0.0107, -0.1523, -0.2168,\n",
      "          -0.7422,  0.2852,  0.4121,  0.9609,  0.0337,  1.2344, -0.4434,\n",
      "          -0.2305,  0.0605, -0.9805, -0.7578]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.5117,  0.1846, -0.6523, -0.2910, -0.7578,  0.1934,  0.3516,\n",
      "           -0.6445],\n",
      "          [ 0.4902,  1.0000, -0.5234,  0.9805,  0.2109, -0.9023,  0.5273,\n",
      "            0.6406],\n",
      "          [ 0.6367, -0.4141, -0.1797,  0.3398, -0.0840, -0.7656,  0.2832,\n",
      "            0.8242],\n",
      "          [ 0.6875,  0.3906,  0.9141, -0.5234, -0.6953, -0.5938, -0.9570,\n",
      "           -1.1484]],\n",
      "\n",
      "         [[ 0.4629,  0.4746, -0.0928, -0.6172, -0.5078, -0.3711,  0.6289,\n",
      "           -0.7773],\n",
      "          [ 1.0625,  0.9609, -0.3594,  0.6367,  0.4375, -0.1758, -0.4805,\n",
      "            0.1592],\n",
      "          [-0.4629,  0.1157, -0.8945, -0.7188, -0.8438, -0.1592,  0.5781,\n",
      "            0.9922],\n",
      "          [ 0.0864, -0.8320,  0.5391, -0.5195,  0.4160,  0.4277, -0.3672,\n",
      "           -0.7305]],\n",
      "\n",
      "         [[ 0.4824, -0.3125, -0.8242, -0.4238, -0.8555, -0.0688,  0.0564,\n",
      "           -0.5312],\n",
      "          [ 0.7500,  0.8867, -0.8672,  0.7422,  0.5820, -0.4746,  0.4492,\n",
      "            0.6914],\n",
      "          [ 0.3828, -0.6680, -0.0107, -0.1523, -0.2168, -0.7422,  0.2852,\n",
      "            0.4121],\n",
      "          [ 0.9609,  0.0337,  1.2344, -0.4434, -0.2305,  0.0605, -0.9805,\n",
      "           -0.7578]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.5117,  0.1846, -0.6523, -0.2910, -0.7578,  0.1934,  0.3516,\n",
      "           -0.6445],\n",
      "          [ 0.4629,  0.4746, -0.0928, -0.6172, -0.5078, -0.3711,  0.6289,\n",
      "           -0.7773],\n",
      "          [ 0.4824, -0.3125, -0.8242, -0.4238, -0.8555, -0.0688,  0.0564,\n",
      "           -0.5312]],\n",
      "\n",
      "         [[ 0.4902,  1.0000, -0.5234,  0.9805,  0.2109, -0.9023,  0.5273,\n",
      "            0.6406],\n",
      "          [ 1.0625,  0.9609, -0.3594,  0.6367,  0.4375, -0.1758, -0.4805,\n",
      "            0.1592],\n",
      "          [ 0.7500,  0.8867, -0.8672,  0.7422,  0.5820, -0.4746,  0.4492,\n",
      "            0.6914]],\n",
      "\n",
      "         [[ 0.6367, -0.4141, -0.1797,  0.3398, -0.0840, -0.7656,  0.2832,\n",
      "            0.8242],\n",
      "          [-0.4629,  0.1157, -0.8945, -0.7188, -0.8438, -0.1592,  0.5781,\n",
      "            0.9922],\n",
      "          [ 0.3828, -0.6680, -0.0107, -0.1523, -0.2168, -0.7422,  0.2852,\n",
      "            0.4121]],\n",
      "\n",
      "         [[ 0.6875,  0.3906,  0.9141, -0.5234, -0.6953, -0.5938, -0.9570,\n",
      "           -1.1484],\n",
      "          [ 0.0864, -0.8320,  0.5391, -0.5195,  0.4160,  0.4277, -0.3672,\n",
      "           -0.7305],\n",
      "          [ 0.9609,  0.0337,  1.2344, -0.4434, -0.2305,  0.0605, -0.9805,\n",
      "           -0.7578]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.8633, -0.5625,  0.6484,  0.7070,  0.1172, -0.7773,  0.5508,\n",
      "          -0.2354,  0.8164,  0.4199,  0.7969, -0.6016, -0.8125, -0.5938,\n",
      "          -1.0391, -0.8711,  0.5312,  0.7852, -0.3535,  0.7109,  1.0156,\n",
      "           0.5430, -0.9453, -0.8242, -0.1157, -0.7305, -0.4531, -0.4316,\n",
      "          -0.5703, -0.2256, -0.3730,  0.3164],\n",
      "         [ 0.2598, -0.1904,  0.2197, -0.4023, -0.4961, -0.5859,  0.6016,\n",
      "          -0.0325, -0.3262,  0.4941,  0.5820,  0.4766, -0.1465, -0.2637,\n",
      "           0.0874,  0.2197, -0.4609, -0.7734, -0.5234, -0.1445,  0.4492,\n",
      "           0.1641,  0.3613, -0.6211,  0.2734,  0.4082,  0.0080,  1.0547,\n",
      "           1.0469, -0.1768, -0.1953,  0.0474],\n",
      "         [ 0.5820, -0.4902,  0.6797,  0.4395,  0.4121, -0.8281,  0.3105,\n",
      "          -0.3418,  0.8398,  0.6602,  0.9492, -0.8203, -0.3340, -0.6055,\n",
      "          -0.8359, -1.0859,  0.2021,  0.8555, -0.7422,  0.2637,  0.6758,\n",
      "           1.0703, -1.4062, -0.8398, -0.3066, -1.0234, -0.0035, -0.3223,\n",
      "          -0.4668, -0.2793, -0.4062,  0.2852]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.8633, -0.5625,  0.6484,  0.7070,  0.1172, -0.7773,  0.5508,\n",
      "           -0.2354],\n",
      "          [ 0.8164,  0.4199,  0.7969, -0.6016, -0.8125, -0.5938, -1.0391,\n",
      "           -0.8711],\n",
      "          [ 0.5312,  0.7852, -0.3535,  0.7109,  1.0156,  0.5430, -0.9453,\n",
      "           -0.8242],\n",
      "          [-0.1157, -0.7305, -0.4531, -0.4316, -0.5703, -0.2256, -0.3730,\n",
      "            0.3164]],\n",
      "\n",
      "         [[ 0.2598, -0.1904,  0.2197, -0.4023, -0.4961, -0.5859,  0.6016,\n",
      "           -0.0325],\n",
      "          [-0.3262,  0.4941,  0.5820,  0.4766, -0.1465, -0.2637,  0.0874,\n",
      "            0.2197],\n",
      "          [-0.4609, -0.7734, -0.5234, -0.1445,  0.4492,  0.1641,  0.3613,\n",
      "           -0.6211],\n",
      "          [ 0.2734,  0.4082,  0.0080,  1.0547,  1.0469, -0.1768, -0.1953,\n",
      "            0.0474]],\n",
      "\n",
      "         [[ 0.5820, -0.4902,  0.6797,  0.4395,  0.4121, -0.8281,  0.3105,\n",
      "           -0.3418],\n",
      "          [ 0.8398,  0.6602,  0.9492, -0.8203, -0.3340, -0.6055, -0.8359,\n",
      "           -1.0859],\n",
      "          [ 0.2021,  0.8555, -0.7422,  0.2637,  0.6758,  1.0703, -1.4062,\n",
      "           -0.8398],\n",
      "          [-0.3066, -1.0234, -0.0035, -0.3223, -0.4668, -0.2793, -0.4062,\n",
      "            0.2852]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.8633, -0.5625,  0.6484,  0.7070,  0.1172, -0.7773,  0.5508,\n",
      "           -0.2354],\n",
      "          [ 0.2598, -0.1904,  0.2197, -0.4023, -0.4961, -0.5859,  0.6016,\n",
      "           -0.0325],\n",
      "          [ 0.5820, -0.4902,  0.6797,  0.4395,  0.4121, -0.8281,  0.3105,\n",
      "           -0.3418]],\n",
      "\n",
      "         [[ 0.8164,  0.4199,  0.7969, -0.6016, -0.8125, -0.5938, -1.0391,\n",
      "           -0.8711],\n",
      "          [-0.3262,  0.4941,  0.5820,  0.4766, -0.1465, -0.2637,  0.0874,\n",
      "            0.2197],\n",
      "          [ 0.8398,  0.6602,  0.9492, -0.8203, -0.3340, -0.6055, -0.8359,\n",
      "           -1.0859]],\n",
      "\n",
      "         [[ 0.5312,  0.7852, -0.3535,  0.7109,  1.0156,  0.5430, -0.9453,\n",
      "           -0.8242],\n",
      "          [-0.4609, -0.7734, -0.5234, -0.1445,  0.4492,  0.1641,  0.3613,\n",
      "           -0.6211],\n",
      "          [ 0.2021,  0.8555, -0.7422,  0.2637,  0.6758,  1.0703, -1.4062,\n",
      "           -0.8398]],\n",
      "\n",
      "         [[-0.1157, -0.7305, -0.4531, -0.4316, -0.5703, -0.2256, -0.3730,\n",
      "            0.3164],\n",
      "          [ 0.2734,  0.4082,  0.0080,  1.0547,  1.0469, -0.1768, -0.1953,\n",
      "            0.0474],\n",
      "          [-0.3066, -1.0234, -0.0035, -0.3223, -0.4668, -0.2793, -0.4062,\n",
      "            0.2852]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.5547,  0.1543,  0.1416,  0.4727, -0.4609,  0.7852, -0.1260,\n",
      "          -0.4336, -0.8750,  0.7734,  0.2451,  0.0430,  0.1982,  0.6836,\n",
      "          -0.0220,  0.2363,  0.1289, -0.9219,  0.4375, -0.6328,  0.8516,\n",
      "           0.4551,  0.0684, -0.6250, -0.8398,  0.1982,  0.8789,  0.4121,\n",
      "           0.1211,  1.1172, -0.0245,  1.0938],\n",
      "         [ 0.0757,  0.2041,  1.0703, -0.1104, -0.2070, -0.3008, -0.8828,\n",
      "          -0.1089,  0.4629,  0.3242, -0.0923,  0.6211, -0.9805, -0.3906,\n",
      "           0.4434,  0.8477, -1.1719, -0.3672,  0.4512,  0.9062, -0.0342,\n",
      "           0.3223,  0.8711, -0.4766,  0.3926, -0.8125, -0.4004, -0.0605,\n",
      "          -0.2910,  0.3730, -0.3613,  0.0356],\n",
      "         [ 0.4883,  0.1089, -0.1924,  0.8945,  0.3867,  0.7344,  0.6367,\n",
      "           0.2910, -0.3457, -0.2793, -0.3613,  0.0811,  0.4590,  0.6875,\n",
      "           1.0938,  0.1709,  0.2930,  0.2871,  0.6055,  0.5352,  0.7031,\n",
      "          -0.0859, -0.0547, -0.1973,  0.1807,  0.6094, -0.4062,  0.6797,\n",
      "           1.0156,  0.3730, -0.5898,  0.4746]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.5547,  0.1543,  0.1416,  0.4727, -0.4609,  0.7852, -0.1260,\n",
      "           -0.4336],\n",
      "          [-0.8750,  0.7734,  0.2451,  0.0430,  0.1982,  0.6836, -0.0220,\n",
      "            0.2363],\n",
      "          [ 0.1289, -0.9219,  0.4375, -0.6328,  0.8516,  0.4551,  0.0684,\n",
      "           -0.6250],\n",
      "          [-0.8398,  0.1982,  0.8789,  0.4121,  0.1211,  1.1172, -0.0245,\n",
      "            1.0938]],\n",
      "\n",
      "         [[ 0.0757,  0.2041,  1.0703, -0.1104, -0.2070, -0.3008, -0.8828,\n",
      "           -0.1089],\n",
      "          [ 0.4629,  0.3242, -0.0923,  0.6211, -0.9805, -0.3906,  0.4434,\n",
      "            0.8477],\n",
      "          [-1.1719, -0.3672,  0.4512,  0.9062, -0.0342,  0.3223,  0.8711,\n",
      "           -0.4766],\n",
      "          [ 0.3926, -0.8125, -0.4004, -0.0605, -0.2910,  0.3730, -0.3613,\n",
      "            0.0356]],\n",
      "\n",
      "         [[ 0.4883,  0.1089, -0.1924,  0.8945,  0.3867,  0.7344,  0.6367,\n",
      "            0.2910],\n",
      "          [-0.3457, -0.2793, -0.3613,  0.0811,  0.4590,  0.6875,  1.0938,\n",
      "            0.1709],\n",
      "          [ 0.2930,  0.2871,  0.6055,  0.5352,  0.7031, -0.0859, -0.0547,\n",
      "           -0.1973],\n",
      "          [ 0.1807,  0.6094, -0.4062,  0.6797,  1.0156,  0.3730, -0.5898,\n",
      "            0.4746]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.5547,  0.1543,  0.1416,  0.4727, -0.4609,  0.7852, -0.1260,\n",
      "           -0.4336],\n",
      "          [ 0.0757,  0.2041,  1.0703, -0.1104, -0.2070, -0.3008, -0.8828,\n",
      "           -0.1089],\n",
      "          [ 0.4883,  0.1089, -0.1924,  0.8945,  0.3867,  0.7344,  0.6367,\n",
      "            0.2910]],\n",
      "\n",
      "         [[-0.8750,  0.7734,  0.2451,  0.0430,  0.1982,  0.6836, -0.0220,\n",
      "            0.2363],\n",
      "          [ 0.4629,  0.3242, -0.0923,  0.6211, -0.9805, -0.3906,  0.4434,\n",
      "            0.8477],\n",
      "          [-0.3457, -0.2793, -0.3613,  0.0811,  0.4590,  0.6875,  1.0938,\n",
      "            0.1709]],\n",
      "\n",
      "         [[ 0.1289, -0.9219,  0.4375, -0.6328,  0.8516,  0.4551,  0.0684,\n",
      "           -0.6250],\n",
      "          [-1.1719, -0.3672,  0.4512,  0.9062, -0.0342,  0.3223,  0.8711,\n",
      "           -0.4766],\n",
      "          [ 0.2930,  0.2871,  0.6055,  0.5352,  0.7031, -0.0859, -0.0547,\n",
      "           -0.1973]],\n",
      "\n",
      "         [[-0.8398,  0.1982,  0.8789,  0.4121,  0.1211,  1.1172, -0.0245,\n",
      "            1.0938],\n",
      "          [ 0.3926, -0.8125, -0.4004, -0.0605, -0.2910,  0.3730, -0.3613,\n",
      "            0.0356],\n",
      "          [ 0.1807,  0.6094, -0.4062,  0.6797,  1.0156,  0.3730, -0.5898,\n",
      "            0.4746]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 0.2256, -0.8047, -0.4668, -0.6172, -0.8047, -0.1709, -0.8398,\n",
      "          -0.6445,  0.3281, -0.1377, -0.1592,  0.3281,  0.6758, -0.5742,\n",
      "          -0.3125,  0.4531,  0.0513,  0.7578, -0.0586,  0.1406, -0.5391,\n",
      "          -0.7969,  0.3906,  0.8945, -0.9648,  0.4082,  0.3105,  0.2422,\n",
      "          -0.7617, -0.2520, -0.1895, -0.4980],\n",
      "         [ 0.5039, -0.4551, -0.4668,  0.7383, -0.5039, -1.1953,  0.3301,\n",
      "          -0.1738, -0.5156,  1.2656,  0.6719,  0.1582, -0.8086,  0.8398,\n",
      "           0.0430,  0.3027, -0.0510,  0.4688, -0.3965,  0.0776, -0.8828,\n",
      "           0.6680, -0.2148,  0.1387, -0.2852, -0.5430, -0.1084, -0.0854,\n",
      "          -0.9688, -0.3125, -0.0737,  0.8828],\n",
      "         [ 0.1206, -0.1436, -0.0493, -0.5039, -0.2793,  0.4688, -0.7969,\n",
      "          -0.1826,  0.7305, -0.8281, -0.0312,  0.5508,  0.7656, -0.6133,\n",
      "          -0.8477,  0.4082,  0.6992,  0.1289,  0.2031, -0.3867,  0.0635,\n",
      "          -1.2812,  0.8125,  0.2373, -0.5234,  0.9961, -0.0371, -0.0752,\n",
      "           0.0623, -0.4414, -0.6328, -0.7930]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 0.2256, -0.8047, -0.4668, -0.6172, -0.8047, -0.1709, -0.8398,\n",
      "           -0.6445],\n",
      "          [ 0.3281, -0.1377, -0.1592,  0.3281,  0.6758, -0.5742, -0.3125,\n",
      "            0.4531],\n",
      "          [ 0.0513,  0.7578, -0.0586,  0.1406, -0.5391, -0.7969,  0.3906,\n",
      "            0.8945],\n",
      "          [-0.9648,  0.4082,  0.3105,  0.2422, -0.7617, -0.2520, -0.1895,\n",
      "           -0.4980]],\n",
      "\n",
      "         [[ 0.5039, -0.4551, -0.4668,  0.7383, -0.5039, -1.1953,  0.3301,\n",
      "           -0.1738],\n",
      "          [-0.5156,  1.2656,  0.6719,  0.1582, -0.8086,  0.8398,  0.0430,\n",
      "            0.3027],\n",
      "          [-0.0510,  0.4688, -0.3965,  0.0776, -0.8828,  0.6680, -0.2148,\n",
      "            0.1387],\n",
      "          [-0.2852, -0.5430, -0.1084, -0.0854, -0.9688, -0.3125, -0.0737,\n",
      "            0.8828]],\n",
      "\n",
      "         [[ 0.1206, -0.1436, -0.0493, -0.5039, -0.2793,  0.4688, -0.7969,\n",
      "           -0.1826],\n",
      "          [ 0.7305, -0.8281, -0.0312,  0.5508,  0.7656, -0.6133, -0.8477,\n",
      "            0.4082],\n",
      "          [ 0.6992,  0.1289,  0.2031, -0.3867,  0.0635, -1.2812,  0.8125,\n",
      "            0.2373],\n",
      "          [-0.5234,  0.9961, -0.0371, -0.0752,  0.0623, -0.4414, -0.6328,\n",
      "           -0.7930]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 0.2256, -0.8047, -0.4668, -0.6172, -0.8047, -0.1709, -0.8398,\n",
      "           -0.6445],\n",
      "          [ 0.5039, -0.4551, -0.4668,  0.7383, -0.5039, -1.1953,  0.3301,\n",
      "           -0.1738],\n",
      "          [ 0.1206, -0.1436, -0.0493, -0.5039, -0.2793,  0.4688, -0.7969,\n",
      "           -0.1826]],\n",
      "\n",
      "         [[ 0.3281, -0.1377, -0.1592,  0.3281,  0.6758, -0.5742, -0.3125,\n",
      "            0.4531],\n",
      "          [-0.5156,  1.2656,  0.6719,  0.1582, -0.8086,  0.8398,  0.0430,\n",
      "            0.3027],\n",
      "          [ 0.7305, -0.8281, -0.0312,  0.5508,  0.7656, -0.6133, -0.8477,\n",
      "            0.4082]],\n",
      "\n",
      "         [[ 0.0513,  0.7578, -0.0586,  0.1406, -0.5391, -0.7969,  0.3906,\n",
      "            0.8945],\n",
      "          [-0.0510,  0.4688, -0.3965,  0.0776, -0.8828,  0.6680, -0.2148,\n",
      "            0.1387],\n",
      "          [ 0.6992,  0.1289,  0.2031, -0.3867,  0.0635, -1.2812,  0.8125,\n",
      "            0.2373]],\n",
      "\n",
      "         [[-0.9648,  0.4082,  0.3105,  0.2422, -0.7617, -0.2520, -0.1895,\n",
      "           -0.4980],\n",
      "          [-0.2852, -0.5430, -0.1084, -0.0854, -0.9688, -0.3125, -0.0737,\n",
      "            0.8828],\n",
      "          [-0.5234,  0.9961, -0.0371, -0.0752,  0.0623, -0.4414, -0.6328,\n",
      "           -0.7930]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[-0.5664, -1.0703,  0.1875,  0.5664,  0.3770, -0.0151,  0.2734,\n",
      "           0.6406, -1.0078,  0.4980,  0.4141, -0.1670,  0.8281,  1.1016,\n",
      "          -0.8555, -1.0312,  0.2324,  0.1050,  0.4844,  0.0513,  0.4980,\n",
      "          -0.5781,  0.2832, -0.6172, -0.3301, -0.0459, -0.3867,  0.0267,\n",
      "          -0.2773,  0.1030, -0.6133,  0.7695],\n",
      "         [ 0.7656, -0.1147,  0.3613, -0.8750,  0.8125, -1.0938, -0.1777,\n",
      "           0.8281, -0.6328,  0.0140,  0.8828, -0.8438,  0.9062,  0.6562,\n",
      "          -0.3750, -0.2217,  0.4805,  0.8047,  0.1543,  0.3438, -0.3223,\n",
      "          -1.3125, -0.3418, -0.5234, -0.2295, -0.7227,  0.8398, -0.9883,\n",
      "          -0.7227,  0.7461, -0.8047,  0.8086],\n",
      "         [-1.0547, -0.2441, -0.6367,  0.9180, -0.0977,  0.4824,  1.0859,\n",
      "           0.3711, -0.0060,  1.1641, -0.1118, -0.1621,  0.5117,  0.6289,\n",
      "          -0.9492, -0.0138,  0.1953, -0.3789,  0.2197,  0.4629, -0.2656,\n",
      "           0.1445,  0.0437,  0.2451, -0.0674,  0.3418, -0.1729,  0.2754,\n",
      "           0.4277, -0.0427,  0.0474,  0.2139]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[-0.5664, -1.0703,  0.1875,  0.5664,  0.3770, -0.0151,  0.2734,\n",
      "            0.6406],\n",
      "          [-1.0078,  0.4980,  0.4141, -0.1670,  0.8281,  1.1016, -0.8555,\n",
      "           -1.0312],\n",
      "          [ 0.2324,  0.1050,  0.4844,  0.0513,  0.4980, -0.5781,  0.2832,\n",
      "           -0.6172],\n",
      "          [-0.3301, -0.0459, -0.3867,  0.0267, -0.2773,  0.1030, -0.6133,\n",
      "            0.7695]],\n",
      "\n",
      "         [[ 0.7656, -0.1147,  0.3613, -0.8750,  0.8125, -1.0938, -0.1777,\n",
      "            0.8281],\n",
      "          [-0.6328,  0.0140,  0.8828, -0.8438,  0.9062,  0.6562, -0.3750,\n",
      "           -0.2217],\n",
      "          [ 0.4805,  0.8047,  0.1543,  0.3438, -0.3223, -1.3125, -0.3418,\n",
      "           -0.5234],\n",
      "          [-0.2295, -0.7227,  0.8398, -0.9883, -0.7227,  0.7461, -0.8047,\n",
      "            0.8086]],\n",
      "\n",
      "         [[-1.0547, -0.2441, -0.6367,  0.9180, -0.0977,  0.4824,  1.0859,\n",
      "            0.3711],\n",
      "          [-0.0060,  1.1641, -0.1118, -0.1621,  0.5117,  0.6289, -0.9492,\n",
      "           -0.0138],\n",
      "          [ 0.1953, -0.3789,  0.2197,  0.4629, -0.2656,  0.1445,  0.0437,\n",
      "            0.2451],\n",
      "          [-0.0674,  0.3418, -0.1729,  0.2754,  0.4277, -0.0427,  0.0474,\n",
      "            0.2139]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[-0.5664, -1.0703,  0.1875,  0.5664,  0.3770, -0.0151,  0.2734,\n",
      "            0.6406],\n",
      "          [ 0.7656, -0.1147,  0.3613, -0.8750,  0.8125, -1.0938, -0.1777,\n",
      "            0.8281],\n",
      "          [-1.0547, -0.2441, -0.6367,  0.9180, -0.0977,  0.4824,  1.0859,\n",
      "            0.3711]],\n",
      "\n",
      "         [[-1.0078,  0.4980,  0.4141, -0.1670,  0.8281,  1.1016, -0.8555,\n",
      "           -1.0312],\n",
      "          [-0.6328,  0.0140,  0.8828, -0.8438,  0.9062,  0.6562, -0.3750,\n",
      "           -0.2217],\n",
      "          [-0.0060,  1.1641, -0.1118, -0.1621,  0.5117,  0.6289, -0.9492,\n",
      "           -0.0138]],\n",
      "\n",
      "         [[ 0.2324,  0.1050,  0.4844,  0.0513,  0.4980, -0.5781,  0.2832,\n",
      "           -0.6172],\n",
      "          [ 0.4805,  0.8047,  0.1543,  0.3438, -0.3223, -1.3125, -0.3418,\n",
      "           -0.5234],\n",
      "          [ 0.1953, -0.3789,  0.2197,  0.4629, -0.2656,  0.1445,  0.0437,\n",
      "            0.2451]],\n",
      "\n",
      "         [[-0.3301, -0.0459, -0.3867,  0.0267, -0.2773,  0.1030, -0.6133,\n",
      "            0.7695],\n",
      "          [-0.2295, -0.7227,  0.8398, -0.9883, -0.7227,  0.7461, -0.8047,\n",
      "            0.8086],\n",
      "          [-0.0674,  0.3418, -0.1729,  0.2754,  0.4277, -0.0427,  0.0474,\n",
      "            0.2139]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n",
      "tensor([[[ 1.0703,  0.0776, -0.5234, -0.1147, -0.3984,  0.3223,  0.1445,\n",
      "          -0.2695,  0.7383, -0.3770, -0.3926,  0.3516,  0.9297,  0.8750,\n",
      "           0.8672, -0.2520, -0.9922,  0.4141,  0.8320,  0.5156, -0.4160,\n",
      "           0.2002, -0.0894,  0.4023, -0.6133, -0.2305, -0.0654, -0.2500,\n",
      "          -0.9453,  0.9023, -0.4316, -0.1089],\n",
      "         [ 1.0859,  0.4941,  0.1357, -0.7812, -0.3984,  0.1553, -0.9258,\n",
      "          -0.7812,  0.5703,  0.8906,  0.6797,  0.0527,  0.4238,  0.0806,\n",
      "           1.2188, -0.3633, -0.8047, -0.3086,  0.3359, -0.3418, -0.3926,\n",
      "          -0.4570, -0.2158,  0.2539,  0.3359, -1.1953, -0.0471,  1.2188,\n",
      "          -0.3008,  0.4004, -0.5898,  1.2188],\n",
      "         [ 0.0645, -0.0586, -0.7500,  0.7070,  0.0991, -0.2012,  0.4707,\n",
      "           0.3730,  0.5469, -0.5625, -1.0078,  1.0000,  0.8359,  1.1484,\n",
      "          -0.1172, -0.5117, -0.0493,  0.6328,  1.0312, -0.0251,  0.3594,\n",
      "           0.6406,  0.6367, -0.2070, -0.8164,  0.2676, -0.5781, -0.5586,\n",
      "          -0.6562,  0.9453, -0.1738, -0.5938]]], dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "initial querys shape: torch.Size([1, 3, 32])\n",
      "params 1 3 4 8\n",
      "tensor([[[[ 1.0703,  0.0776, -0.5234, -0.1147, -0.3984,  0.3223,  0.1445,\n",
      "           -0.2695],\n",
      "          [ 0.7383, -0.3770, -0.3926,  0.3516,  0.9297,  0.8750,  0.8672,\n",
      "           -0.2520],\n",
      "          [-0.9922,  0.4141,  0.8320,  0.5156, -0.4160,  0.2002, -0.0894,\n",
      "            0.4023],\n",
      "          [-0.6133, -0.2305, -0.0654, -0.2500, -0.9453,  0.9023, -0.4316,\n",
      "           -0.1089]],\n",
      "\n",
      "         [[ 1.0859,  0.4941,  0.1357, -0.7812, -0.3984,  0.1553, -0.9258,\n",
      "           -0.7812],\n",
      "          [ 0.5703,  0.8906,  0.6797,  0.0527,  0.4238,  0.0806,  1.2188,\n",
      "           -0.3633],\n",
      "          [-0.8047, -0.3086,  0.3359, -0.3418, -0.3926, -0.4570, -0.2158,\n",
      "            0.2539],\n",
      "          [ 0.3359, -1.1953, -0.0471,  1.2188, -0.3008,  0.4004, -0.5898,\n",
      "            1.2188]],\n",
      "\n",
      "         [[ 0.0645, -0.0586, -0.7500,  0.7070,  0.0991, -0.2012,  0.4707,\n",
      "            0.3730],\n",
      "          [ 0.5469, -0.5625, -1.0078,  1.0000,  0.8359,  1.1484, -0.1172,\n",
      "           -0.5117],\n",
      "          [-0.0493,  0.6328,  1.0312, -0.0251,  0.3594,  0.6406,  0.6367,\n",
      "           -0.2070],\n",
      "          [-0.8164,  0.2676, -0.5781, -0.5586, -0.6562,  0.9453, -0.1738,\n",
      "           -0.5938]]]], dtype=torch.bfloat16, grad_fn=<ViewBackward0>)\n",
      "after view querys shape: torch.Size([1, 3, 4, 8])\n",
      "tensor([[[[ 1.0703,  0.0776, -0.5234, -0.1147, -0.3984,  0.3223,  0.1445,\n",
      "           -0.2695],\n",
      "          [ 1.0859,  0.4941,  0.1357, -0.7812, -0.3984,  0.1553, -0.9258,\n",
      "           -0.7812],\n",
      "          [ 0.0645, -0.0586, -0.7500,  0.7070,  0.0991, -0.2012,  0.4707,\n",
      "            0.3730]],\n",
      "\n",
      "         [[ 0.7383, -0.3770, -0.3926,  0.3516,  0.9297,  0.8750,  0.8672,\n",
      "           -0.2520],\n",
      "          [ 0.5703,  0.8906,  0.6797,  0.0527,  0.4238,  0.0806,  1.2188,\n",
      "           -0.3633],\n",
      "          [ 0.5469, -0.5625, -1.0078,  1.0000,  0.8359,  1.1484, -0.1172,\n",
      "           -0.5117]],\n",
      "\n",
      "         [[-0.9922,  0.4141,  0.8320,  0.5156, -0.4160,  0.2002, -0.0894,\n",
      "            0.4023],\n",
      "          [-0.8047, -0.3086,  0.3359, -0.3418, -0.3926, -0.4570, -0.2158,\n",
      "            0.2539],\n",
      "          [-0.0493,  0.6328,  1.0312, -0.0251,  0.3594,  0.6406,  0.6367,\n",
      "           -0.2070]],\n",
      "\n",
      "         [[-0.6133, -0.2305, -0.0654, -0.2500, -0.9453,  0.9023, -0.4316,\n",
      "           -0.1089],\n",
      "          [ 0.3359, -1.1953, -0.0471,  1.2188, -0.3008,  0.4004, -0.5898,\n",
      "            1.2188],\n",
      "          [-0.8164,  0.2676, -0.5781, -0.5586, -0.6562,  0.9453, -0.1738,\n",
      "           -0.5938]]]], dtype=torch.bfloat16, grad_fn=<TransposeBackward0>)\n",
      "after transpose querys shape: torch.Size([1, 4, 3, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1143,  0.0312,  0.5078,  0.1875,  0.6836,  0.1572, -0.2285,\n",
       "           0.3027,  0.9648,  0.1719, -0.6094, -1.0156, -0.6328,  0.7227,\n",
       "          -0.4980,  0.7422, -0.2129,  0.0618, -0.3770,  0.7500, -0.9023,\n",
       "          -0.4180, -0.4004, -0.4902,  0.7539,  0.5039, -0.2656,  0.7617,\n",
       "          -0.4551, -0.5273,  0.1348, -0.1162, -0.2676,  0.7852, -0.3379,\n",
       "          -0.2109,  0.8789, -0.4453, -0.4180, -0.4141, -0.3594,  0.6055,\n",
       "          -0.1357, -0.9023],\n",
       "         [ 0.1064,  0.9297,  0.0928, -0.0649,  0.4395, -0.5664, -0.0564,\n",
       "          -1.1172,  0.3105, -0.2354, -0.4355, -0.6680, -0.7617, -0.2246,\n",
       "          -0.5977, -0.4043, -0.2852, -0.4980,  0.1396,  0.0659,  0.0781,\n",
       "           0.4922,  0.7070,  0.0762,  0.4160,  0.0088,  0.4570,  0.5977,\n",
       "           0.2891,  0.1924,  0.2158, -1.1406,  0.4766,  0.0986,  0.9570,\n",
       "          -0.5117, -0.1914,  0.0364, -0.5703, -1.2344, -1.1875,  0.2910,\n",
       "           0.8359, -0.3281],\n",
       "         [-0.4863, -0.4258,  0.5938,  0.9492,  0.5781,  0.9453,  0.0181,\n",
       "           0.9336,  0.1602,  0.5156, -0.1084,  0.0713,  0.2520,  0.9102,\n",
       "          -0.4316,  1.1172, -0.0791,  0.7305, -1.1562,  0.6367, -0.9180,\n",
       "          -1.0703, -0.4043, -0.4746, -0.3574,  0.8828, -0.7188,  0.3633,\n",
       "           0.1895, -0.0698, -0.4492,  0.4238, -1.0547,  0.3809, -0.4961,\n",
       "           0.1069,  0.8672,  0.1514,  0.0291,  0.2852,  0.4434,  0.4434,\n",
       "          -0.6172, -0.5781]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1, 2, 3]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549324d6-5c71-4147-ae21-2e67675faa3d",
   "metadata": {
    "id": "549324d6-5c71-4147-ae21-2e67675faa3d"
   },
   "source": [
    "&nbsp;\n",
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c",
   "metadata": {
    "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c"
   },
   "source": [
    "- Check out the [README.md](./README.md), to use this model via the `llms_from_scratch` package\n",
    "- For those interested in a comprehensive guide on building a large language model from scratch and gaining a deeper understanding of its mechanics, you might like my [Build a Large Language Model (From Scratch)](http://mng.bz/orYv)\n",
    "\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
